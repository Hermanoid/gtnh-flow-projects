{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PuLP dependency to seriously simplify setting up LP problem. It's just a wrapper to help set things up,\n",
    "#  but it does come with a built-in solver (which we will also use)\n",
    "from pulp import LpVariable, LpProblem, LpMinimize, lpDot, LpStatus, value\n",
    "import numpy as np\n",
    "\n",
    "from src.graph import Graph\n",
    "from src.graph._preProcessing import connectGraph, removeBackEdges\n",
    "from src.data.basicTypes import Ingredient, IngredientCollection, Recipe\n",
    "from factory_graph import ProgramContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPSolver:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.variables = []\n",
    "        # self.variable_idx_counter = 0 # Autogen current \"head\" index for variable number\n",
    "        # self.system = []\n",
    "        self.solved_vars = None # Result from linear solver\n",
    "\n",
    "        self.lookup = {} # (machine, product, direction, multi_idx) -> variable index\n",
    "        self.edge_from_perspective_to_index = {} # (edge, machine_id) -> variable index\n",
    "\n",
    "def graphPreProcessing(self):\n",
    "    connectGraph(self)\n",
    "    # if not self.graph_config.get('KEEP_BACK_EDGES', False):\n",
    "    #     removeBackEdges(self)\n",
    "    Graph.createAdjacencyList(self)\n",
    "\n",
    "def linearProgrammingSolver(self: ProgramContext, project_name: str, recipes: list[Recipe], graph_config: dict):\n",
    "    g = Graph(project_name, recipes, self, graph_config=graph_config)\n",
    "    self._graph = g # For test access\n",
    "    graphPreProcessing(g)\n",
    "    print(g.adj)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function createAdjacencyList.<locals>.<lambda> at 0x000001E0C02A8540>, {'source': defaultdict(<class 'list'>, {'O': [('source', '0', 'pams fish')]}), '0': defaultdict(<class 'list'>, {'I': [('source', '0', 'pams fish')], 'O': [('0', '1', 'methane')]}), '1': defaultdict(<class 'list'>, {'I': [('0', '1', 'methane')], 'O': [('1', 'sink', 'biogas')]}), 'sink': defaultdict(<class 'list'>, {'I': [('1', 'sink', 'biogas')]})})\n"
     ]
    }
   ],
   "source": [
    "context = ProgramContext()\n",
    "\n",
    "context.graph_gen = linearProgrammingSolver # Override solver\n",
    "context.generate_one(\"power/fish/methane.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is me figuring out edge cases.\n",
    "\n",
    "\"\"\"\n",
    "- m: centrifuge\n",
    "  tier: LV\n",
    "  I:\n",
    "    pams fish: 1\n",
    "  O:\n",
    "    methane: 96\n",
    "  eut: 5\n",
    "  dur: 19\n",
    "  number: 1\n",
    "  cost_priority:\n",
    "    pams fish: 1\n",
    "  # target:\n",
    "  #   # methane: 250\n",
    "  #   pams fish: 1\n",
    "- m: distillery\n",
    "  tier: LV\n",
    "  I:\n",
    "    methane: 125\n",
    "  O:\n",
    "    biogas: 375\n",
    "  eut: 7\n",
    "  dur: 1\n",
    "\"\"\"\n",
    "\n",
    "#  \n",
    "\n",
    "problem = LpProblem(\"test\", LpMinimize)\n",
    "cost_inputs = [\"pams fish\"]\n",
    "recipe_vars = [\"pams fish\", \"methane\"]\n",
    "items = [\"pams fish\", \"methane\", \"biogas\"]\n",
    "target_vector = [0,0,1000]\n",
    "ing_matrix = {\n",
    "  \"fuge\": [-1, 96, 0],\n",
    "  \"dist\": [0, -125, 375]\n",
    "}\n",
    "# How do you figure out which variables should be inputs?\n",
    "input_vectors = {\n",
    "  \"fish_in\": [1, 0, 0],\n",
    "}\n",
    "# rec_mat = np.array(list(recipe_vectors.values())+ list(input_vectors.values()))\n",
    "# display(rec_mat)\n",
    "# rec_mat.transpose()\n",
    "all_vectors = ing_matrix.copy()\n",
    "all_vectors.update(input_vectors)\n",
    "# Item constraints are transpose of values of constraint vectors (all vectors)\n",
    "item_constraints = np.array(list(all_vectors.values())).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optimal'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem.variables()\n",
    "# Create variables\n",
    "recipe_vars = LpVariable.dicts(\"rec\", all_vectors.keys(), lowBound=0, cat=\"Continuous\")\n",
    "\n",
    "# Add objective\n",
    "problem += recipe_vars[\"fish_in\"]\n",
    "# Add constraints\n",
    "for item_constraint_vec, target in zip(item_constraints, target_vector):\n",
    "    problem += lpDot(recipe_vars.values(), item_constraint_vec) >= target\n",
    "# problem += lpDot(x.values(), target_vector) >= 0\n",
    "\n",
    "problem.solve()\n",
    "LpStatus[problem.status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec_dist = 2.6666667\n",
      "rec_fish_in = 3.4722222\n",
      "rec_fuge = 3.4722222\n"
     ]
    }
   ],
   "source": [
    "for v in problem.variables():\n",
    "    print(v.name, \"=\", v.varValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0]]),\n",
       " (0, 1, 2))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That works, now let's mess around with ways to identify input candidates\n",
    "# Cases that need to be inputs are useful to report the user, \n",
    "# but we want to find \"eliminated\" variables as described by https://github.com/ClaudeMetz/FactoryPlanner/blob/master/modfiles/backend/calculation/matrix_engine.lua\n",
    "# - that is, variables that are net-zero after all loops/etc and don't need to be system inputs.\n",
    "\n",
    "# I'm theorizing that the \"eliminated\" variables might be findable via the reduced row echelon form of the matrix.\n",
    "\n",
    "from sympy import Matrix\n",
    "# m = Matrix(np.hstack([item_constraints, np.array(target_vector).reshape(-1,1)]))\n",
    "# m.rref()\n",
    "\n",
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    " \n",
    "positive_cost_cycle = Matrix(pall_loop)\n",
    " \n",
    "positive_cost_cycle.rref()\n",
    "#  Oh yeah, duh, rref on an over-defined matrix. Uhhhh\n",
    "# This matrix converts recipe executions to items produced, \n",
    "# and solving it finds necessary recipes executions/unit time to produce desired items\n",
    "# We're looking for input-item-to-output item conversions. How do we find those?\n",
    "# - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [  -0.0123427693881819,     0.999920219926959, -0.00266637715277894],\n",
       " [    0.999921784104044,     0.012337578452739, -0.00197762613328934],\n",
       " [ 0.000975236276396803,   0.00201218158793192,    0.688745946762978],\n",
       " [ -0.00175569605886587,  -0.00179957317684196,   -0.724995172566176],\n",
       " [-0.000219462003270191, -0.000224946177417711,   1.0320007302374e-6]]),\n",
       " Matrix([\n",
       " [9056.0851669197,                0,                0],\n",
       " [              0, 993.812582692507,                0],\n",
       " [              0,                0, 1.37930382200068]]),\n",
       " Matrix([\n",
       " [  0.111777170775024,   -0.99373329625207,  3.6777441977233e-6],\n",
       " [ -0.993733296258832,  -0.111777170773151, 7.11721275761968e-7],\n",
       " [2.96173288126787e-7, 3.73425105498543e-6,   0.999999999992984]]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cost_cycle.singular_value_decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1000000 & -1000000 & 1000 & 0 & 0\\\\-1000000 & 82000000 & 80000 & -144000 & -18000\\\\1000 & 80000 & 82.9025 & -144.95 & -18\\\\0 & -144000 & -144.95 & 257 & 32\\\\0 & -18000 & -18 & 32 & 4\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[ 1000000, -1000000,    1000,       0,      0],\n",
       "[-1000000, 82000000,   80000, -144000, -18000],\n",
       "[    1000,    80000, 82.9025, -144.95,    -18],\n",
       "[       0,  -144000, -144.95,     257,     32],\n",
       "[       0,   -18000,     -18,      32,      4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cost_cycle * positive_cost_cycle.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0],\n",
       " [0, 1]]),\n",
       " (0, 1))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpler_pos_cost = Matrix([\n",
    "    [-1, 2],\n",
    "    [0.25, -1]\n",
    "])\n",
    "simpler_pos_cost.rref()\n",
    "# I don't think this is going to work for determining which should be inputs, but I think I can figure it out using LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    "target_vector = [0, 0, 0, 0, 10]\n",
    "\n",
    "# New theory: for anything that is ever an input, make an input vector, but tell LP to minimize number used\n",
    "# Possible upgrade: seek to maximize earliness of inputs in a topological sort or derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well poop.\n",
      "Non-constant expressions cannot be multiplied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pulp\\pulp.py:1316: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    }
   ],
   "source": [
    "# Priorities: [recipe tax, pall enriched ammonia, additional vector cost]\n",
    "priority_ratio = 9000/0.95 # Smallest/biggest\n",
    "\n",
    "from pulp import LpProblem, LpMinimize, LpBinary, LpVariable, value, lpSum, lpDot\n",
    "\n",
    "problem = LpProblem(\"min input test\", LpMinimize)\n",
    "recipe_vars = LpVariable.dicts(\"recipe\",  [\"lcr pall met pow recycle\", \"lcr repre\", \"sifter salt recycle\"],0)\n",
    "variables =  [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\", \"repre salt\"] \n",
    "# Filtered only by things that are ever an input\n",
    "inputs = [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\"] \n",
    "explicit_inputs = [\"pall enriched ammonia\"]\n",
    "explicit_input_amounts = LpVariable.dicts(\"input\", explicit_inputs, 0)\n",
    "# Filtered to remove explicit inputs\n",
    "additional_inputs = [\"ammonia\", \"pall met pow\", \"pall salt\"] \n",
    "additional_input_subtractors = LpVariable.dicts(\"input\", additional_inputs, 0)\n",
    "additional_input_switches = LpVariable.dicts(\"in_switch\", additional_inputs, cat=LpBinary)\n",
    "try:\n",
    "    for item, recipe_coeffs, target in zip(variables, pall_loop, target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in explicit_inputs:\n",
    "            input_term = explicit_input_amounts[item]\n",
    "        elif item in additional_inputs:\n",
    "            input_term = additional_input_subtractors[item] * additional_input_switches[item]\n",
    "        else:\n",
    "            input_term = 0\n",
    "        problem += lpDot(recipe_vars.values(), recipe_coeffs) + input_term >= target\n",
    "        \n",
    "    # Objective, in increasing order of priority:\n",
    "    # 1: Per-recipe tax\n",
    "    # (2, n-1): explicit costs to minimize (explicit inputs)\n",
    "    # n: High-cost additional inputs\n",
    "    problem += (priority_ratio**0 * lpSum(recipe_vars.values())\n",
    "        + priority_ratio**1 * explicit_input_amounts[\"pall enriched ammonia\"]\n",
    "        + priority_ratio**2 * lpSum(additional_input_switches))\n",
    "except TypeError as e:\n",
    "    print(\"Well poop.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little essay about a new approach to solve this which-inputs-should-we-choose problem:\n",
    "\n",
    "# Alright, so making the linear optimizer solve for minimal inputs while also solving the problem ain't going to work.\n",
    "# ... because this formulation is quadratic and I can't think of a nice model that isn't.\n",
    "# ... we could get rid of the toggle and treat new inputs cumulatively as the highest priority class\n",
    "# ... but that has lots of edge cases and naturally gives a higher weight to minimizing large-number stuff, like fluids.\n",
    "# ... we could counteract *that* by normalizing quantities (so 9000L of oxygen becomes 9kL of oxygen, or a less nice unit)\n",
    "# ... but I can't think of a good normalization scheme that doesn't have problems with the different ranges of quantities between recipes.\n",
    "\n",
    "# New insight: Focus on solving for minimal inputs first, then solve problem.\n",
    "# Model this as a cover problem: we want to find the smallest set of inputs which reaches the inputs of all recipes.\n",
    "\n",
    "# We can once again use Linear Optimization to solve this problem.\n",
    "# We want to find the minimum number of inputs we must provide so that every recipe *can* be run.\n",
    "# We want to prioritize hitting every recipe, *then* minimizing the number of inputs.\n",
    "# Note that the linear optimizer might not use all resources if it choses not to include a relevant recipe in a solution.\n",
    "# Note that if you can run a parent recipe (e.g. ammonia and oxygen for nitric acid), \n",
    "# ... you can run descendent recipes (e.g. nitric acid [and ammonia] for ammonium chloride)\n",
    "\n",
    "# I'm going to model this as a bipartite graph in my head.\n",
    "# - Every resource that is ever an input to any recipe becomes a requirement (constraint in LP terms)\n",
    "#       - (one for oxygen, hydrochloric, ilmenite, whatever)\n",
    "#       - These are nodes on the right-hand side of the graph.\n",
    "#       - These are the inputs to \"cover\" with as few new/raw/actual inputs as possible. \n",
    "#       - I will call them \"requirement\" resources to avoid confusing myself.\n",
    "# - We also take this same list of inputs and make a binary (on or off) variable for every resource\n",
    "#       - Picture these as nodes on the left-hand side of the graph\n",
    "#       - Turning on these inputs corresponds to selecting that variable as an input.\n",
    "#       - I will call them \"providable\" resources to avoid confusing myself.\n",
    "# - In graph terms, we put an edge between every providable resource and the requirements it covers. This includes:\n",
    "#       - The resource itself (providing oxygen obviously covers oxygen requirements)\n",
    "#       - For every recipe which uses this resource, cover all of its outputs\n",
    "#       - For all of *those* resources, keep covering - this becomes DFS.\n",
    "#       - In LP terms, every constraint is sum(every binary variable that covers this required resource) >= 1\n",
    "# - Finally, the objective is the minimize the sum of all those binary variables (aka find fewest selected inputs)\n",
    "# - As a preprocessing step, all requirements that are indirectly covered by explicitly provided inputs can be deleted.\n",
    "\n",
    "# Something in my head tickles that this is NP-Complete, but I don't feel like putting in the work to test/prove it.\n",
    "# Regardless, LP solvers can totally tackle NPC problems like Knapsack (and they're reasonably optimized about it)\n",
    "\n",
    "# One big issue with this approach: selecting a valuable resource before a loop \n",
    "# (for example, palladium salt dust, which loops around and indirectly supplies *many* recipes)\n",
    "# ... will have high value and cover many resources. \n",
    "# Theory #1: We could use a heuristic-based \"cyclic graph toposort\" to minimize back-edges (loop-backs)\n",
    "# ... use that sort to form a DAG that mostly moves ingredient->output, and then use this algorithm\n",
    "# Theory #2: By the nature of most GTNH recipe graphs, especially when at least one start-of-the-chain ingredient has been provided,\n",
    "# ... a solution which uses just-before-a-loop resources as an input won't usually be \"minimal\".\n",
    "# Further, this algorithm doesn't need to *perfectly* solve this problem, \n",
    "# ... because the user can fix wierd behavior by explicitly providing more resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    "target_vector = [0, 0, 0, 0, 10]\n",
    "item_recipe_covers = {\n",
    "    \"ammonia\": {\"lcr pall met pow recycle\": {\"pall enriched ammonia\"}},\n",
    "    \"pall met pow\": {\"lcr pall met pow recycle\": {\"pall enriched ammonia\"}},\n",
    "    \"pall enriched ammonia\": {\"lcr repre\": {\"pall salt\", \"repre pall\"}},\n",
    "    \"pall met pow\": {\"lcr repre\": {\"pall salt\", \"repre pall\"}},\n",
    "    \"pall salt\":{\"sifter salt recycle\": {\"pall met pow\"}}\n",
    "}\n",
    "recipes = {\n",
    "    \"lcr pall met pow recycle\": {\n",
    "        \"I\": {\"ammonia\":1000, \"pall met pow\": 1},\n",
    "        \"O\": {\"pall enriched ammonia\": 1000},\n",
    "    },\n",
    "    \"lcr repre\": {\n",
    "        \"I\": {\"pall enriched ammonia\": 9000, \"pall met pow\": 9},\n",
    "        \"O\": {\"pall salt\": 16, \"repre pall\": 2},\n",
    "    },\n",
    "    \"sifter salt recycle\": {\n",
    "        \"I\": {\"pall salt\": 1},\n",
    "        \"O\": {\"pall met pow\": 0.95},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from src.data.loadMachines import recipesFromConfig\n",
    "def genSlug(s, try_acronym=False):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9_]\", \"\", re.sub(r\"\\W+\", \"_\", s.lower()))\n",
    "    words = slug.split(\"_\")\n",
    "    if len(slug) > 25 or (try_acronym and len(words)>=2):\n",
    "        return \"\".join(word[0] for word in words)\n",
    "    else:\n",
    "        return slug\n",
    "\n",
    "def genRecipeNames(recipes):\n",
    "    counter = Counter()\n",
    "    # name_map = {\"sink\": \"sink\", \"source\": \"source\"}\n",
    "    names = []\n",
    "    for recipe in recipes:\n",
    "        name = genSlug(recipe.machine, True) + \"_\" + genSlug(recipe.I[0].name)\n",
    "        if name in counter:\n",
    "            counter[name] += 1\n",
    "            name += f\"_{counter[name]}\"\n",
    "        names.append(name)\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'palladium enriched ammonia': {'palladium enriched ammonia',\n",
       "  'palladium metallic powder dust',\n",
       "  'palladium salt dust',\n",
       "  'reprecipitated palladium dust'},\n",
       " 'ammonia': {'ammonia',\n",
       "  'palladium enriched ammonia',\n",
       "  'palladium metallic powder dust',\n",
       "  'palladium salt dust',\n",
       "  'reprecipitated palladium dust'},\n",
       " 'palladium metallic powder dust': {'palladium enriched ammonia',\n",
       "  'palladium metallic powder dust',\n",
       "  'palladium salt dust',\n",
       "  'reprecipitated palladium dust'},\n",
       " 'palladium salt dust': {'palladium enriched ammonia',\n",
       "  'palladium metallic powder dust',\n",
       "  'palladium salt dust',\n",
       "  'reprecipitated palladium dust'}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stripBrackets(ing):\n",
    "    prefix = False\n",
    "    if ing[:2] == '\\u2588 ':\n",
    "        prefix = True\n",
    "    stripped = ing.split(']')[-1].strip()\n",
    "    if prefix and stripped[:2] != '\\u2588 ': \n",
    "        stripped = '\\u2588 ' + stripped\n",
    "    return stripped\n",
    "\n",
    "def getItemCovers(recipes):\n",
    "    item_covers = {}\n",
    "\n",
    "    item_to_covered_recipes = {}\n",
    "    recipe_to_covered_items = {}\n",
    "    items_to_cover = set()\n",
    "    # Just use indices to identify recipes here\n",
    "    for covered_recipe, io in enumerate(recipes):\n",
    "        for ing in io.I:\n",
    "            ing_name = stripBrackets(ing.name)\n",
    "            item_to_covered_recipes[ing_name] = item_to_covered_recipes.get(ing_name, []) + [covered_recipe]\n",
    "            items_to_cover.add(ing_name)\n",
    "        for out in io.O:\n",
    "            out_name = stripBrackets(out.name)\n",
    "            recipe_to_covered_items[covered_recipe] = recipe_to_covered_items.get(covered_recipe, []) + [out_name]\n",
    "\n",
    "\n",
    "    # Cheeky DFS for each item to figure out what it covers.\n",
    "    # This could be done all-at-once with some shenanigans, but I think we want to not allow loops on a per-item basis\n",
    "    # My gut is telling me that will be a slightly more restricted/less-prone-to-error heuristic.\n",
    "    for item in items_to_cover:\n",
    "        used_recipes = set()\n",
    "        covered_items = {item}\n",
    "        frontier = [item]\n",
    "        while not len(frontier) == 0:\n",
    "            covered_item = frontier.pop()\n",
    "            if covered_item not in item_to_covered_recipes: continue # item covers no recipes\n",
    "            for covered_recipe in item_to_covered_recipes[covered_item]:\n",
    "                if covered_recipe in used_recipes: continue # Recipe already used (we've looped)\n",
    "                used_recipes.add(covered_recipe)\n",
    "                if covered_recipe not in recipe_to_covered_items: continue # recipe covers no items (we deleted its items in preprocessing)\n",
    "                for outgoing_item in recipe_to_covered_items[covered_recipe]:\n",
    "                    if outgoing_item in covered_items: continue # We've already hit this item\n",
    "                    covered_items.add(outgoing_item)\n",
    "                    frontier.append(outgoing_item)\n",
    "        item_covers[item] = covered_items\n",
    "    return item_covers\n",
    "recipes = recipesFromConfig(\"devtest/palladium_loop.yaml\")\n",
    "getItemCovers(recipes)\n",
    "# Only ammonia covers ammonia (good), but I think this loopy example is a bad example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chlorine': 11,\n",
       " 'magnesium chloride dust': 11,\n",
       " 'bauxite dust': 15,\n",
       " 'salt': 11,\n",
       " 'magnesium dust': 11,\n",
       " 'titanium tetrachloride': 11,\n",
       " 'rutile dust': 12,\n",
       " 'sodium dust': 11,\n",
       " 'hot titanium ingot': 2,\n",
       " 'carbon dust': 11,\n",
       " 'carbon monoxide': 11}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bauxite_recipes = recipesFromConfig(\"223_bauxite_line.yaml\")\n",
    "baux_covers = getItemCovers(bauxite_recipes)\n",
    "\n",
    "display({item: len(covered) for (item, covered) in baux_covers.items()})\n",
    "set(baux_covers.keys()) - set(baux_covers[\"bauxite dust\"])\n",
    "# That spooked me at first but turns out yeah, bauxite line has one input: bauxite. Lets try another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'scheelite dust': 12,\n",
       " 'endstone dust': 17,\n",
       " 'hydrochloric acid': 13,\n",
       " 'salt': 12,\n",
       " 'hydrogen': 2,\n",
       " 'tungstic acid dust': 3,\n",
       " 'tungsten trioxide dust': 2,\n",
       " 'calcium chloride dust': 12,\n",
       " 'sodium dust': 12,\n",
       " 'sodium hydroxide dust': 12,\n",
       " 'water': 13,\n",
       " 'tungstate dust': 13,\n",
       " 'sodium tungstate': 12}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'hydrochloric acid', 'water'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bauxite_recipes = recipesFromConfig(\"2200_tungstate.yaml\")\n",
    "baux_covers = getItemCovers(bauxite_recipes)\n",
    "\n",
    "display({item: len(covered) for (item, covered) in baux_covers.items()})\n",
    "set(baux_covers.keys()) - set(baux_covers[\"endstone dust\"])\n",
    "# Okay, this finally proves a concern I had - that this binary \"cover/not cover\" approach\n",
    "# won't handle when an input would reach an input, but not *enough*\n",
    "# for tungstate, endstone covers most inputs, but byproduct hydrogen only covers *some* of the needed amount\n",
    "# I thought this might be a non-event, but nay, it's an event. We'll need to start calculating ratios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New essay on how to avoid doing what the last essay was talking about \n",
    "# (solving for min inputs one at a time is hard, lets do it all at once again!)\n",
    "\n",
    "# It might be possible to frame this as an LP (actually just an rref),\n",
    "# but I think it would still require a DFS from me to figure out which recipes to include in the solve\n",
    "# so I'm going to run the ratios myself.\n",
    "# Main Idea: if you run across a recipe you've already seen and think you can cover\n",
    "#   an additional recipe-ingredient using a byproduct, confirm you have enough of that byproduct to meet that requirement.\n",
    "# Problem: what if you attempt this when you don't have enough byproduct, but later another recipe gives you more of that byproduct?\n",
    "# Problem: what if you dfs and hit this recipe with the byproduct ingredient first and the main ingredient later?\n",
    "#   - In this case, you show as producing excess of the main ingredient\n",
    "\n",
    "# Example of this: \"insufficient_byproduct_fake.png\", where a sodium tungstate input can either:\n",
    "#   - Cover the EBF with scheelite, then produce byproduct hydrogen, which is not enough to cover the EBF's hydrogen input \n",
    "#       - This requires an extra hydrogen input, which is desired behavior.\n",
    "#   - Cover the salt LCR with salt for hydrogen, then cover the EBF with hydrogen. \n",
    "#       - When we reach the EBF with scheelite, it looks like we have excess - great! (not desired behavior)\n",
    "\n",
    "#.... poop. I can't think of a way to prioritize \"main ingredients\" like scheelite without requiring a priori knowledge of ingredient value.\n",
    "#   - An LP problem which asks to maximize reachable ingredients will of course use the route that covers both hydrogen and scheelite\n",
    "#   - An LP problem which minimizes reachable ingredients... finds no reachable ingredients?\n",
    "#   - What about an LP problem that is constrained to reach as many ingredients as possible but minimizes out these byproduct events?\n",
    "\n",
    "# AH! Theory: a reformulation of the quadratic issue before. We find a quantity of each input that is  \n",
    "# \"The most this problem could possibly use\" - get to that later. Point is, that's wired to a binary input we want to minimize.\n",
    "# Then, another variable subtracts from that binary-with-big-coefficient number.\n",
    "# If the binary is off, that subtractor goes to zero (no less, because of constraints/bounds), \n",
    "# .... but if it isn't, it's equal to difference from big-number.\n",
    "# Big-number minus subtractor yields amount of the switched-on input. Could work!\n",
    "\n",
    "# But how do we figure out the most an input could possibly need? I don't love the \"1 trillion or so ought to do\" solution.\n",
    "# I think the priority ratio math will still apply: sum of targets * (ratio of smallest to biggest value in problem)\n",
    "# But there could be a setup like:\n",
    "# Biggest-number input (1000 A) produces smallest-number output (0.1 B)\n",
    "# Second-biggest-number input (999 B) produces second-smallest-number output (0.2 C)\n",
    "# ... and so on. Those two would require (999/0.2*1000/0.1) = 49950000.0 units of A for 1 C\n",
    "\n",
    "# This would require some sort of DFS ratio calculation that would be no fun.\n",
    "# I say we use the \"1 trillion or so ought to do strategy\" and include a warning if any subtractor is zero (input 100% used)\n",
    "# ... but no, if that much of an input really is used (maybe a VERY large liquid air distilling problem),\n",
    "# ... then no solution would be found at all! Wait, not true - another input could be used as well.\n",
    "# ... We'll go with this solution.\n",
    "\n",
    "# Choose a BIG_NUMBER that doesn't intrude too far into double precision when LP starts doing its math.\n",
    "# Doubles have ~15 decimal digits of precision. Let's leave... uh... 6? for recipes, leaving 9 for BIG_NUMBER.\n",
    "# 1,000,000,000 - A trillion or so ought to do. That wasn't even intentional.\n",
    "# This problem should be somewhat helped (in not-contrived examples) by input scale normalization (see above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two digits with 1E15 999999999999997.9 999999999999997.9 999999999999997.9\n",
      "Eight Digits with 1E9 999999997.8765432 999999997.8765432 \n",
      "Seven Digits 999999997.8765433 999999997.8765432\n"
     ]
    }
   ],
   "source": [
    "BIG_NUMBER = 1E15\n",
    "print(\"Two digits with 1E15\", BIG_NUMBER-2.16, BIG_NUMBER-2.12, BIG_NUMBER-2.09)\n",
    "# NO, BAD - not enough precision.\n",
    "BIG_NUMBER = 1E9\n",
    "print(\"Eight Digits with 1E9\", BIG_NUMBER-2.12345678, BIG_NUMBER-2.12345679, \"\\nSeven Digits\", BIG_NUMBER-2.1234567, BIG_NUMBER-2.1234568)\n",
    "# I suppose it's not so surprising when math does what it is supposed to do, but it's neat to see that (almost) work.\n",
    "# Bc floats use exponents, the first 2 gets divided to 1, which is implicit in a float (so that digit doesn't count towards precision).\n",
    "# I would have wanted to see Seven Digits not work bc it should be 6, but I probably chose numbers that fit\n",
    "# into the gaps of \"Approximately\" 6 digits of precision.\n",
    "# Let's try this approach with some problems and see what happens when we reduce BIG_NUMBER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New LP Plan:\n",
    "# Constraints: (recipe contributions) + ingredient_switch*BIG_NUMBER - ingredient_subtractor >= target\n",
    "# Objective Priorities (low->high):\n",
    "# 0: Recipe Tax (unweighted sum of recipe amounts to avoid unnecessary work)\n",
    "# (1, n-2): Explicit Ingredient Priorities (ratio**k * (sum of n-priority explicit ingredient vectors))\n",
    "# n-1: Additional Ingredient Quantities (sum)\n",
    "# n: Ingredient Switches (sum)\n",
    "\n",
    "# Note that this prioritizes not using an ingredient at all over using less of it\n",
    "# and it prioritizes using explicit ingredients before additional ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Status Infeasible\n",
      "\n",
      "Switches\n",
      "ammonia 3.1\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Subtractors\n",
      "ammonia 0.0\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Recipe vars\n",
      "lcr pall met pow recycle 31.0\n",
      "lcr repre 5.0\n",
      "sifter salt recycle 80.0\n",
      "\n",
      "Explicit Ingredient Vars\n",
      "pall enriched ammonia 14000.0\n",
      "\n",
      "Constraints: \n",
      "ammonia 31.0 * -1000 [lcr pall met pow recycle] + 5.0 * 0 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 31000.0 = 0.0 >= 0\n",
      "pall enriched ammonia 31.0 * 1000 [lcr pall met pow recycle] + 5.0 * -9000 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 14000.0 = 0.0 >= 0\n",
      "pall met pow 31.0 * -1 [lcr pall met pow recycle] + 5.0 * -9 [lcr repre] + 80.0 * 0.95 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "pall salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 16 [lcr repre] + 80.0 * -1 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "repre salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 2 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 0 = 10.0 >= 10\n"
     ]
    }
   ],
   "source": [
    "# Priorities: [recipe tax, pall enriched ammonia, additional input amounts, additional input switches]\n",
    "priority_ratio = 9000/0.95 # Smallest/biggest\n",
    "BIG_NUMBER = 1E9\n",
    "\n",
    "from pulp import LpProblem, LpMinimize, LpBinary, LpVariable, value, lpSum, lpDot\n",
    "\n",
    "def solveProblem(big_number):\n",
    "    problem = LpProblem(\"min input v2\", LpMinimize)\n",
    "    recipe_vars = LpVariable.dicts(\"recipe\",  [\"lcr pall met pow recycle\", \"lcr repre\", \"sifter salt recycle\"],0)\n",
    "    variables =  [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\", \"repre salt\"] \n",
    "    # Filtered only by things that are ever an input\n",
    "    inputs = [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\"] \n",
    "    explicit_inputs = [\"pall enriched ammonia\"]\n",
    "    explicit_input_amounts = LpVariable.dicts(\"input\", explicit_inputs, 0)\n",
    "    # Filtered to remove explicit inputs\n",
    "    additional_inputs = [\"ammonia\", \"pall met pow\", \"pall salt\"]\n",
    "    additional_input_subtractors = LpVariable.dicts(\"input\", additional_inputs, 0, 1)\n",
    "    additional_input_switches = LpVariable.dicts(\"in_switch\", additional_inputs, 0, 1, cat=LpBinary)\n",
    "\n",
    "\n",
    "    for item, recipe_coeffs, target in zip(variables, pall_loop, target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in explicit_inputs:\n",
    "            input_term = explicit_input_amounts[item]\n",
    "        elif item in additional_inputs:\n",
    "            # input_term = 0\n",
    "            input_term = big_number * (additional_input_switches[item] - additional_input_subtractors[item])\n",
    "            # Also restrict input to be strictly positive (no inputting negative items)\n",
    "            problem += (additional_input_switches[item] - additional_input_subtractors[item]) >= 0 \n",
    "        else:\n",
    "            input_term = 0\n",
    "        problem += lpDot(recipe_vars.values(), recipe_coeffs) + input_term == target\n",
    "\n",
    "    problem += (priority_ratio**0 * lpSum(recipe_vars.values())\n",
    "        + priority_ratio**1 * lpSum(explicit_input_amounts)\n",
    "        + priority_ratio**2 * -1 * lpSum(additional_input_subtractors.values()) # invert (to max)\n",
    "        + priority_ratio**3 * lpSum(additional_input_switches)\n",
    "    )\n",
    "    problem.solve()\n",
    "    \n",
    "    print(\"Problem Status\", LpStatus[problem.status])\n",
    "\n",
    "    def show_values(var_dict):\n",
    "        for var in var_dict:\n",
    "            print(var, value(var_dict[var]))\n",
    "            \n",
    "    print(\"\\nSwitches\")\n",
    "    show_values(additional_input_switches)\n",
    "    print(\"\\nSubtractors\")\n",
    "    show_values(additional_input_subtractors)\n",
    "    print(\"\\nRecipe vars\")\n",
    "    show_values(recipe_vars)\n",
    "    print(\"\\nExplicit Ingredient Vars\")\n",
    "    show_values(explicit_input_amounts)\n",
    "\n",
    "    print(\"\\nConstraints: \")\n",
    "    for item, recipe_coeffs, target in zip(variables, pall_loop, target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in explicit_inputs:\n",
    "            input_term = value(explicit_input_amounts[item])\n",
    "        elif item in additional_inputs:\n",
    "            input_term = big_number * (value(additional_input_switches[item]) - value(additional_input_subtractors[item]))\n",
    "        else:\n",
    "            input_term = 0\n",
    "        recipe_sum = sum(value(v) * coeff for ((name, v), coeff) in zip(recipe_vars.items(), recipe_coeffs))\n",
    "        coeff_string = \" + \".join([f\"{value(v)} * {coeff} [{name}]\" for ((name, v), coeff) in zip(recipe_vars.items(), recipe_coeffs)])\n",
    "        print(item, f\"{coeff_string} + {input_term} = {recipe_sum+input_term} >= {target}\")\n",
    "solveProblem(1E4)\n",
    "# That is a correct solution! I think there are some edge cases regarding byproduct handling...\n",
    "# There are some cases where you *need* a byproduct (no solution otherwise),\n",
    "# And there are some cases where you *want* a byproduct (a side-recipe cracks e.g. radioactive waste into uranium, etc)\n",
    "# I'll explore solving that next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Status Optimal\n",
      "\n",
      "Switches\n",
      "ammonia 1.0\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Subtractors\n",
      "ammonia 0.69\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Recipe vars\n",
      "lcr pall met pow recycle 31.0\n",
      "lcr repre 5.0\n",
      "sifter salt recycle 80.0\n",
      "\n",
      "Explicit Ingredient Vars\n",
      "pall enriched ammonia 14000.0\n",
      "\n",
      "Constraints: \n",
      "ammonia 31.0 * -1000 [lcr pall met pow recycle] + 5.0 * 0 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 31000.000000000004 = 3.637978807091713e-12 >= 0\n",
      "pall enriched ammonia 31.0 * 1000 [lcr pall met pow recycle] + 5.0 * -9000 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 14000.0 = 0.0 >= 0\n",
      "pall met pow 31.0 * -1 [lcr pall met pow recycle] + 5.0 * -9 [lcr repre] + 80.0 * 0.95 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "pall salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 16 [lcr repre] + 80.0 * -1 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "repre salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 2 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 0 = 10.0 >= 10\n"
     ]
    }
   ],
   "source": [
    "# Find behavior with a nearly-too-small BIG_NUMBER\n",
    "solveProblem(1E5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem Status Infeasible\n",
      "\n",
      "Switches\n",
      "ammonia 3.1\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Subtractors\n",
      "ammonia 0.0\n",
      "pall met pow 0.0\n",
      "pall salt 0.0\n",
      "\n",
      "Recipe vars\n",
      "lcr pall met pow recycle 31.0\n",
      "lcr repre 5.0\n",
      "sifter salt recycle 80.0\n",
      "\n",
      "Explicit Ingredient Vars\n",
      "pall enriched ammonia 14000.0\n",
      "\n",
      "Constraints: \n",
      "ammonia 31.0 * -1000 [lcr pall met pow recycle] + 5.0 * 0 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 31000.0 = 0.0 >= 0\n",
      "pall enriched ammonia 31.0 * 1000 [lcr pall met pow recycle] + 5.0 * -9000 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 14000.0 = 0.0 >= 0\n",
      "pall met pow 31.0 * -1 [lcr pall met pow recycle] + 5.0 * -9 [lcr repre] + 80.0 * 0.95 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "pall salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 16 [lcr repre] + 80.0 * -1 [sifter salt recycle] + 0.0 = 0.0 >= 0\n",
      "repre salt 31.0 * 0 [lcr pall met pow recycle] + 5.0 * 2 [lcr repre] + 80.0 * 0 [sifter salt recycle] + 0 = 10.0 >= 10\n"
     ]
    }
   ],
   "source": [
    "# Find behavior with a too-small BIG_NUMBER\n",
    "solveProblem(1E4)\n",
    "# This failed how we would want to it - straight-out\n",
    "# - but I suspect it will stop failing like this as we ease off on byproduct restrictions for byproduct-y problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'heated bauxite slurry': 0, 'nickel dust': 1, 'antimony dust': 2, 'calcite': 3, 'sluice juice': 4, 'sodium carbonate': 5, 'sodium aluminate': 6, 'water': 7, 'bauxite slag': 8, 'oxygen': 9, 'carbon dioxide': 10, 'gallium': 11, 'hydrogen': 12, 'rutile': 13, 'silicon dioxide': 14, 'sodium hydroxide': 15, 'stone dust': 16, 'aluminium dust': 17, 'purified bauxite': 18, 'carbon dust': 19, 'copper dust': 20, 'quicklime': 21, 'bauxite slurry': 22, 'alumina': 23, 'sodium dust': 24, 'iron dust': 25, 'tin dust': 26, 'steam': 27, 'aluminium hydroxide': 28}\n",
      "Recipe Vectors [('mixer_purified_bauxite', [0, 0, 0, 0, 0, 0, 0, -5, 0, 0, 0, 0, 0, 0, 0, -3, 0, 0, -32, 0, 0, -4, 8, 0, 0, 0, 0, 0, 0]), ('oc_steam', [32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -32, 0, 0, 0, 0, -2, 0]), ('lcr_carbon_dioxide', [-32, 0, 0, 10, 5, 9, 0, 0, 16, 0, -5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, -1]), ('lcr_calcite', [0, 0, 0, -5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0]), ('centrifuge_bauxite_slag', [0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 3, 0, 1, 9, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 8, 0, 0, 0]), ('centrifuge_sluice_juice', [0, 0.2, 0.2, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0.2, 0, 0, 0, 0, 0.4, 0.2, 0, 0]), ('electrolyzer_sodium_carbonate', [0, 0, 0, 0, 0, -6, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 2, 0, 0, 0, 0]), ('lcr_sodium_dust', [0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]), ('lcr_aluminium_dust', [0, 0, 0, 0, 0, 0, 16, -16, 0, 0, 0, 0, 48, 0, 0, -16, 0, -16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), ('lcr_sodium_aluminate', [0, 0, 0, 0, 0, 0, -1, -2, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7])]\n",
      "{'heated bauxite slurry', 'sodium hydroxide', 'aluminium dust', 'calcite', 'purified bauxite', 'sluice juice', 'sodium carbonate', 'sodium aluminate', 'water', 'bauxite slag', 'quicklime', 'carbon dioxide', 'bauxite slurry', 'sodium dust', 'steam', 'aluminium hydroxide'}\n",
      "Desired Byproducts: {'silicon dioxide', 'copper dust', 'nickel dust', 'antimony dust', 'gallium', 'stone dust', 'hydrogen', 'rutile', 'iron dust', 'tin dust', 'carbon dust', 'oxygen'}\n",
      "Minimized Byproducts: {'heated bauxite slurry', 'carbon dioxide', 'sodium hydroxide', 'quicklime', 'bauxite slurry', 'aluminium hydroxide', 'aluminium dust', 'alumina', 'sodium dust', 'calcite', 'sluice juice', 'sodium carbonate', 'sodium aluminate', 'purified bauxite', 'steam', 'water', 'bauxite slag'}\n",
      "Problem Status: Optimal in 0.0779999999795109 cpu-seconds\n",
      "\n",
      "Switches\n",
      "heated bauxite slurry 0.0\n",
      "sodium hydroxide 1.0\n",
      "aluminium dust 0.0\n",
      "calcite 0.0\n",
      "purified bauxite 1.0\n",
      "sluice juice 0.0\n",
      "sodium carbonate 0.0\n",
      "sodium aluminate 1.0\n",
      "water 1.0\n",
      "bauxite slag 0.0\n",
      "quicklime 0.0\n",
      "carbon dioxide 1.0\n",
      "bauxite slurry 0.0\n",
      "sodium dust 0.0\n",
      "steam 1.0\n",
      "aluminium hydroxide 0.0\n",
      "\n",
      "Subtractors\n",
      "heated bauxite slurry 0.0\n",
      "sodium hydroxide 0.99889286\n",
      "aluminium dust 0.0\n",
      "calcite 0.0\n",
      "purified bauxite 0.984\n",
      "sluice juice 0.0\n",
      "sodium carbonate 0.0\n",
      "sodium aluminate 0.99998214\n",
      "water 0.99708929\n",
      "bauxite slag 0.0\n",
      "quicklime 0.0\n",
      "carbon dioxide 0.999625\n",
      "bauxite slurry 0.0\n",
      "sodium dust 0.0\n",
      "steam 0.99975\n",
      "aluminium hydroxide 0.0\n",
      "\n",
      "Recipe vars\n",
      "mixer_purified_bauxite 5.0\n",
      "oc_steam 1.25\n",
      "lcr_carbon_dioxide 1.25\n",
      "lcr_calcite 2.5\n",
      "centrifuge_bauxite_slag 7.5\n",
      "centrifuge_sluice_juice 6.25\n",
      "electrolyzer_sodium_carbonate 1.875\n",
      "lcr_sodium_dust 3.75\n",
      "lcr_aluminium_dust 0.0\n",
      "lcr_sodium_aluminate 0.17857143\n",
      "\n",
      "Explicit Ingredient Vars\n",
      "\n",
      "Surplus Vars\n",
      "heated bauxite slurry 0.0\n",
      "nickel dust 1.25\n",
      "antimony dust 1.25\n",
      "calcite 0.0\n",
      "sluice juice 0.0\n",
      "sodium carbonate 0.0\n",
      "sodium aluminate 0.0\n",
      "water 0.0\n",
      "bauxite slag 12.5\n",
      "oxygen 5.625\n",
      "carbon dioxide 0.0\n",
      "gallium 22.5\n",
      "hydrogen 3.75\n",
      "rutile 7.5\n",
      "silicon dioxide 67.5\n",
      "sodium hydroxide 0.0\n",
      "stone dust 6.25\n",
      "aluminium dust 0.0\n",
      "purified bauxite 0.0\n",
      "carbon dust 1.875\n",
      "copper dust 1.25\n",
      "quicklime 0.0\n",
      "bauxite slurry 0.0\n",
      "alumina 0.0\n",
      "sodium dust 0.0\n",
      "iron dust 62.5\n",
      "tin dust 1.25\n",
      "steam 0.0\n",
      "aluminium hydroxide 0.0\n",
      "\n",
      "Constraints: \n",
      "heated bauxite slurry 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 32 [oc_steam] + 1.25 * -32 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "nickel dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0.2 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 1.25 == 0 + 1.25\n",
      "antimony dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0.2 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 1.25 == 0 + 1.25\n",
      "calcite 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 10 [lcr_carbon_dioxide] + 2.5 * -5 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "sluice juice 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 5 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * -1 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "sodium carbonate 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 9 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * -6 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "sodium aluminate 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 16 [lcr_aluminium_dust] + 0.17857143 * -1 [lcr_sodium_aluminate] + 0.1786000000003618 = 2.8570000361799464e-05 == 0 + 0.0\n",
      "water 5.0 * -5 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * -1 [lcr_sodium_dust] + 0.0 * -16 [lcr_aluminium_dust] + 0.17857143 * -2 [lcr_sodium_aluminate] + 29.107099999999832 = -4.286000016762159e-05 == 0 + 0.0\n",
      "bauxite slag 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 16 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * -1 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 12.5 == 0 + 12.5\n",
      "oxygen 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 3 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 5.625 == 0 + 5.625\n",
      "carbon dioxide 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * -5 [lcr_carbon_dioxide] + 2.5 * 1 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 3.750000000000142 = 1.4210854715202004e-13 == 0 + 0.0\n",
      "gallium 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 3 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 22.5 == 0 + 22.5\n",
      "hydrogen 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 1 [lcr_sodium_dust] + 0.0 * 48 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 3.75 == 0 + 3.75\n",
      "rutile 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 1 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 7.5 == 0 + 7.5\n",
      "silicon dioxide 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 9 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 67.5 == 0 + 67.5\n",
      "sodium hydroxide 5.0 * -3 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 1 [lcr_sodium_dust] + 0.0 * -16 [lcr_aluminium_dust] + 0.17857143 * 1 [lcr_sodium_aluminate] + 11.071400000000065 = -2.85699999356126e-05 == 0 + 0.0\n",
      "stone dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 1 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 6.25 == 0 + 6.25\n",
      "aluminium dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * -16 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "purified bauxite 5.0 * -32 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 160.00000000000014 = 1.4210854715202004e-13 == 0 + 0.0\n",
      "carbon dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 1 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 1.875 == 0 + 1.875\n",
      "copper dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0.2 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 1.25 == 0 + 1.25\n",
      "quicklime 5.0 * -4 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 2 [lcr_calcite] + 7.5 * 2 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "bauxite slurry 5.0 * 8 [mixer_purified_bauxite] + 1.25 * -32 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "alumina 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 8 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 10.0 == 10 + 0.0\n",
      "sodium dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 2 [electrolyzer_sodium_carbonate] + 3.75 * -1 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0.0 = 0.0 == 0 + 0.0\n",
      "iron dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 8 [centrifuge_bauxite_slag] + 6.25 * 0.4 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 62.5 == 0 + 62.5\n",
      "tin dust 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0.2 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 0 = 1.25 == 0 + 1.25\n",
      "steam 5.0 * 0 [mixer_purified_bauxite] + 1.25 * -2 [oc_steam] + 1.25 * 0 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 0 [lcr_sodium_aluminate] + 2.4999999999997247 = -2.753353101070388e-13 == 0 + 0.0\n",
      "aluminium hydroxide 5.0 * 0 [mixer_purified_bauxite] + 1.25 * 0 [oc_steam] + 1.25 * -1 [lcr_carbon_dioxide] + 2.5 * 0 [lcr_calcite] + 7.5 * 0 [centrifuge_bauxite_slag] + 6.25 * 0 [centrifuge_sluice_juice] + 1.875 * 0 [electrolyzer_sodium_carbonate] + 3.75 * 0 [lcr_sodium_dust] + 0.0 * 0 [lcr_aluminium_dust] + 0.17857143 * 7 [lcr_sodium_aluminate] + 0.0 = 9.99999993922529e-09 == 0 + 0.0\n"
     ]
    }
   ],
   "source": [
    "# Modify the solver to use generic problems and allow penalized byproducts.\n",
    "\n",
    "# Priorities: [recipe tax, pall enriched ammonia, additional input amounts, additional input switches, byproducts]\n",
    "priority_ratio = 39/0.2*5 # biggest/Smallest\n",
    "BIG_NUMBER = 1E4\n",
    "\n",
    "from pulp import LpProblem, LpMinimize, LpBinary, LpVariable, value, lpSum, lpDot\n",
    "from collections import Counter\n",
    "\n",
    "def genSlug(s, try_acronym=False):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9_]\", \"\", re.sub(r\"\\W+\", \"_\", s.lower()))\n",
    "    words = slug.split(\"_\")\n",
    "    if len(slug) > 40 or (try_acronym and len(words)>=2):\n",
    "        return \"\".join(word[0] for word in words if len(word) > 0)\n",
    "    else:\n",
    "        return slug[:25]\n",
    "\n",
    "def genRecipeNames(recipes):\n",
    "    counter = Counter()\n",
    "    names = []\n",
    "    for recipe in recipes:\n",
    "        name = genSlug(recipe.machine, True) + \"_\" + genSlug(recipe.I[0].name)\n",
    "        if name in counter:\n",
    "            counter[name] += 1\n",
    "            name += f\"_{counter[name]}\"\n",
    "        names.append(name)\n",
    "    return names\n",
    "\n",
    "class LpProject:\n",
    "    def __init__(self, inputs, explicit_inputs, outputs, targets, variables, recipe_names, ing_matrix, target_vector):\n",
    "        self.inputs = inputs\n",
    "        self.explicit_inputs = explicit_inputs\n",
    "        self.outputs = outputs\n",
    "        self.targets = targets\n",
    "        self.variables = variables\n",
    "        self.recipe_names = recipe_names\n",
    "        self.ing_matrix = ing_matrix\n",
    "        self.target_vector = target_vector\n",
    "        \n",
    "    @staticmethod\n",
    "    def fromRecipes(recipes):\n",
    "        inputs = set()\n",
    "        explicit_inputs = set()\n",
    "        outputs = set()\n",
    "        targets = {}\n",
    "        # Just use indices to identify recipes here\n",
    "        for recipe, io in enumerate(recipes):\n",
    "            for ing in io.I:\n",
    "                ing_name = stripBrackets(ing.name)\n",
    "                inputs.add(ing_name)\n",
    "            for out in io.O:\n",
    "                out_name = stripBrackets(out.name)\n",
    "                outputs.add(out_name)\n",
    "            if hasattr(io, \"cost\"):\n",
    "                for explicit_input in getattr(io, \"cost\"):\n",
    "                    explicit_inputs.add(explicit_input)\n",
    "            if hasattr(io, \"target\"):\n",
    "                for target, quant in getattr(io, \"target\").items():\n",
    "                    targets[target] = quant\n",
    "                    \n",
    "        if not all(target in outputs for target in targets): \n",
    "            raise RuntimeError(\"Encountered target which is never an output (likely a spelling mistake). targets: \" +str(targets))\n",
    "        if not all(cost in inputs for cost in explicit_inputs):\n",
    "            raise RuntimeError(\"Encountered cost/explicit input which is never an input (likely a spelling mistake). costs: \" +str(explicit_inputs))\n",
    "        \n",
    "        variables = list(inputs | outputs)\n",
    "        \n",
    "        recipe_vectors = []\n",
    "        variable_indices = {var: i for i, var in enumerate(variables)}\n",
    "        print(variable_indices)\n",
    "        for recipe in recipes:\n",
    "            vector = [0] * len(variables)\n",
    "            for ing in recipe.I:\n",
    "                vector[variable_indices[stripBrackets(ing.name)]] = -1 * ing.quant\n",
    "            for out in recipe.O:\n",
    "                vector[variable_indices[stripBrackets(out.name)]] = out.quant\n",
    "            recipe_vectors.append(vector)\n",
    "        recipe_names = genRecipeNames(recipes)\n",
    "        print(\"Recipe Vectors\", list(zip(recipe_names, recipe_vectors)))\n",
    "        ing_vectors = list(zip(*recipe_vectors)) # Transpose (constraints are per-item, not per-recipe)\n",
    "        target_vector = [targets.get(var, 0) for var in variables]\n",
    "        \n",
    "        return LpProject(inputs, explicit_inputs, outputs, targets, variables, recipe_names, ing_vectors, target_vector)\n",
    "    \n",
    "    @staticmethod\n",
    "    def fromConfig(config_path):\n",
    "        recipes = recipesFromConfig(config_path)\n",
    "        return LpProject.fromRecipes(recipes)\n",
    "    \n",
    "\n",
    "def solveProblem(recipes):\n",
    "    project = LpProject.fromRecipes(recipes)    \n",
    "    \n",
    "    additional_inputs = project.inputs -project.explicit_inputs\n",
    "    print(additional_inputs)\n",
    "    # Outputs that are only ever outputs (and not targets) are likely desired.        \n",
    "    desired_byproducts = (project.outputs - project.inputs) - set(project.targets.keys())\n",
    "    minimized_byproducts = set(project.variables) - desired_byproducts\n",
    "    \n",
    "    problem = LpProblem(\"gtnh_flow_lp_solver\", LpMinimize)\n",
    "    \n",
    "    recipe_vars = LpVariable.dicts(\"recipe\", project.recipe_names, 0)\n",
    "    explicit_input_amounts = LpVariable.dicts(\"input\", project.explicit_inputs, 0)\n",
    "    additional_input_subtractors = LpVariable.dicts(\"in_sub\", additional_inputs, lowBound= 0, upBound= 1)\n",
    "    additional_input_switches = LpVariable.dicts(\"in_switch\", additional_inputs, 0, 1, cat=LpBinary)\n",
    "    byproduct_amounts = LpVariable.dicts(\"byproduct\", project.variables, 0)\n",
    "\n",
    "    for item, recipe_coeffs, target in zip(project.variables, project.ing_matrix, project.target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in project.explicit_inputs:\n",
    "            input_term = explicit_input_amounts[item]\n",
    "        elif item in additional_inputs:\n",
    "            # input_term = 0\n",
    "            input_term = BIG_NUMBER * (additional_input_switches[item] - additional_input_subtractors[item])\n",
    "            # Also restrict input to be strictly positive (no inputting negative items)\n",
    "            problem += (additional_input_switches[item] - additional_input_subtractors[item]) >= 0 \n",
    "        else:\n",
    "            input_term = 0\n",
    "        \n",
    "        # Most of the time, products beyond the target should be heavily penalized\n",
    "        # to encourage using other recipes to reprocess them.\n",
    "        # However, some items are the output of byproduct processing (like uranium from radioactive waste byproduct)\n",
    "        # our heuristic is that if something is only output (never an input), it should have a small production priority\n",
    "        problem += lpDot(recipe_vars.values(), recipe_coeffs) + input_term == target + byproduct_amounts[item]\n",
    "        # problem += lpDot(recipe_vars.values(), recipe_coeffs) + input_term == target\n",
    "\n",
    "    desired_byproduct_amounts = [byproduct_amounts[var] for var in desired_byproducts]\n",
    "    minimized_byproduct_amounts = [byproduct_amounts[var] for var in minimized_byproducts]\n",
    "    print(\"Desired Byproducts:\", desired_byproducts)\n",
    "    print(\"Minimized Byproducts:\", minimized_byproducts)\n",
    "    problem += (priority_ratio**0 * lpSum(recipe_vars)\n",
    "        + priority_ratio**1 * -1 * lpSum(desired_byproduct_amounts) # Byproducts are lowest priority (nearly)\n",
    "        + priority_ratio**2 * lpSum(explicit_input_amounts)\n",
    "        + priority_ratio**3 * -1 * lpSum(additional_input_subtractors) # invert (to max)\n",
    "        + priority_ratio**4 * 2 * lpSum(additional_input_switches) # Subtractors are <= 1, so we can use smaller priority step\n",
    "        + priority_ratio**4 * 4 * lpSum(minimized_byproduct_amounts) # Same as above\n",
    "    )\n",
    "    problem.solve()\n",
    "    \n",
    "    print(\"Problem Status:\", LpStatus[problem.status], \"in\", problem.solutionCpuTime, \"cpu-seconds\")\n",
    "\n",
    "    def show_values(var_dict):\n",
    "        for var in var_dict:\n",
    "            print(var, value(var_dict[var]))\n",
    "            \n",
    "    print(\"\\nSwitches\")\n",
    "    show_values(additional_input_switches)\n",
    "    print(\"\\nSubtractors\")\n",
    "    show_values(additional_input_subtractors)\n",
    "    print(\"\\nRecipe vars\")\n",
    "    show_values(recipe_vars)\n",
    "    print(\"\\nExplicit Ingredient Vars\")\n",
    "    show_values(explicit_input_amounts)\n",
    "    print(\"\\nSurplus Vars\")\n",
    "    show_values(byproduct_amounts)\n",
    "\n",
    "    print(\"\\nConstraints: \")\n",
    "    for item, recipe_coeffs, target in zip(project.variables, project.ing_matrix, project.target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in project.explicit_inputs:\n",
    "            input_term = value(explicit_input_amounts[item])\n",
    "        elif item in additional_inputs:\n",
    "            input_term = BIG_NUMBER * (value(additional_input_switches[item]) - value(additional_input_subtractors[item]))\n",
    "        else:\n",
    "            input_term = 0\n",
    "        recipe_sum = sum(value(v) * coeff for ((name, v), coeff) in zip(recipe_vars.items(), recipe_coeffs))\n",
    "        coeff_string = \" + \".join([f\"{value(v)} * {coeff} [{name}]\" for ((name, v), coeff) in zip(recipe_vars.items(), recipe_coeffs)])\n",
    "        surplus_term = value(byproduct_amounts[item])\n",
    "        print(item, f\"{coeff_string} + {input_term} = {recipe_sum+input_term} == {target} + {surplus_term}\")\n",
    "    return problem\n",
    "        \n",
    "# recipes = recipesFromConfig(\"devtest/insufficient_byproduct_fake.yaml\")\n",
    "recipes = recipesFromConfig(\"devtest/bauxite.yaml\")\n",
    "# recipes = recipesFromConfig(\"devtest/palladium_loop.yaml\")\n",
    "problem = solveProblem(recipes)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('_C1',\n",
       "              -1*in_sub_heated_bauxite_slurry + 1*in_switch_heated_bauxite_slurry + 0 >= 0),\n",
       "             ('_C2',\n",
       "              -1*byproduct_heated_bauxite_slurry + -10000.0*in_sub_heated_bauxite_slurry + 10000.0*in_switch_heated_bauxite_slurry + -32*recipe_lcr_carbon_dioxide + 32*recipe_oc_steam + 0.0 = 0),\n",
       "             ('_C3',\n",
       "              -1*byproduct_nickel_dust + 0.2*recipe_centrifuge_sluice_juice + 0.0 = 0),\n",
       "             ('_C4',\n",
       "              -1*byproduct_antimony_dust + 0.2*recipe_centrifuge_sluice_juice + 0.0 = 0),\n",
       "             ('_C5', -1*in_sub_calcite + 1*in_switch_calcite + 0 >= 0),\n",
       "             ('_C6',\n",
       "              -1*byproduct_calcite + -10000.0*in_sub_calcite + 10000.0*in_switch_calcite + -5*recipe_lcr_calcite + 10*recipe_lcr_carbon_dioxide + 0.0 = 0),\n",
       "             ('_C7',\n",
       "              -1*in_sub_sluice_juice + 1*in_switch_sluice_juice + 0 >= 0),\n",
       "             ('_C8',\n",
       "              -1*byproduct_sluice_juice + -10000.0*in_sub_sluice_juice + 10000.0*in_switch_sluice_juice + -1*recipe_centrifuge_sluice_juice + 5*recipe_lcr_carbon_dioxide + 0.0 = 0),\n",
       "             ('_C9',\n",
       "              -1*in_sub_sodium_carbonate + 1*in_switch_sodium_carbonate + 0 >= 0),\n",
       "             ('_C10',\n",
       "              -1*byproduct_sodium_carbonate + -10000.0*in_sub_sodium_carbonate + 10000.0*in_switch_sodium_carbonate + -6*recipe_electrolyzer_sodium_carbonate + 9*recipe_lcr_carbon_dioxide + 0.0 = 0),\n",
       "             ('_C11',\n",
       "              -1*in_sub_sodium_aluminate + 1*in_switch_sodium_aluminate + 0 >= 0),\n",
       "             ('_C12',\n",
       "              -1*byproduct_sodium_aluminate + -10000.0*in_sub_sodium_aluminate + 10000.0*in_switch_sodium_aluminate + 16*recipe_lcr_aluminium_dust + -1*recipe_lcr_sodium_aluminate + 0.0 = 0),\n",
       "             ('_C13', -1*in_sub_water + 1*in_switch_water + 0 >= 0),\n",
       "             ('_C14',\n",
       "              -1*byproduct_water + -10000.0*in_sub_water + 10000.0*in_switch_water + -16*recipe_lcr_aluminium_dust + -2*recipe_lcr_sodium_aluminate + -1*recipe_lcr_sodium_dust + -5*recipe_mixer_purified_bauxite + 0.0 = 0),\n",
       "             ('_C15',\n",
       "              -1*in_sub_bauxite_slag + 1*in_switch_bauxite_slag + 0 >= 0),\n",
       "             ('_C16',\n",
       "              -1*byproduct_bauxite_slag + -10000.0*in_sub_bauxite_slag + 10000.0*in_switch_bauxite_slag + -1*recipe_centrifuge_bauxite_slag + 16*recipe_lcr_carbon_dioxide + 0.0 = 0),\n",
       "             ('_C17',\n",
       "              -1*byproduct_oxygen + 3*recipe_electrolyzer_sodium_carbonate + 0 = 0),\n",
       "             ('_C18',\n",
       "              -1*in_sub_carbon_dioxide + 1*in_switch_carbon_dioxide + 0 >= 0),\n",
       "             ('_C19',\n",
       "              -1*byproduct_carbon_dioxide + -10000.0*in_sub_carbon_dioxide + 10000.0*in_switch_carbon_dioxide + 1*recipe_lcr_calcite + -5*recipe_lcr_carbon_dioxide + 0.0 = 0),\n",
       "             ('_C20',\n",
       "              -1*byproduct_gallium + 3*recipe_centrifuge_bauxite_slag + 0 = 0),\n",
       "             ('_C21',\n",
       "              -1*byproduct_hydrogen + 48*recipe_lcr_aluminium_dust + 1*recipe_lcr_sodium_dust + 0 = 0),\n",
       "             ('_C22',\n",
       "              -1*byproduct_rutile + 1*recipe_centrifuge_bauxite_slag + 0 = 0),\n",
       "             ('_C23',\n",
       "              -1*byproduct_silicon_dioxide + 9*recipe_centrifuge_bauxite_slag + 0 = 0),\n",
       "             ('_C24',\n",
       "              -1*in_sub_sodium_hydroxide + 1*in_switch_sodium_hydroxide + 0 >= 0),\n",
       "             ('_C25',\n",
       "              -1*byproduct_sodium_hydroxide + -10000.0*in_sub_sodium_hydroxide + 10000.0*in_switch_sodium_hydroxide + -16*recipe_lcr_aluminium_dust + 1*recipe_lcr_sodium_aluminate + 1*recipe_lcr_sodium_dust + -3*recipe_mixer_purified_bauxite + 0.0 = 0),\n",
       "             ('_C26',\n",
       "              -1*byproduct_stone_dust + 1*recipe_centrifuge_sluice_juice + 0 = 0),\n",
       "             ('_C27',\n",
       "              -1*in_sub_aluminium_dust + 1*in_switch_aluminium_dust + 0 >= 0),\n",
       "             ('_C28',\n",
       "              -1*byproduct_aluminium_dust + -10000.0*in_sub_aluminium_dust + 10000.0*in_switch_aluminium_dust + -16*recipe_lcr_aluminium_dust + 0.0 = 0),\n",
       "             ('_C29',\n",
       "              -1*in_sub_purified_bauxite + 1*in_switch_purified_bauxite + 0 >= 0),\n",
       "             ('_C30',\n",
       "              -1*byproduct_purified_bauxite + -10000.0*in_sub_purified_bauxite + 10000.0*in_switch_purified_bauxite + -32*recipe_mixer_purified_bauxite + 0.0 = 0),\n",
       "             ('_C31',\n",
       "              -1*byproduct_carbon_dust + 1*recipe_electrolyzer_sodium_carbonate + 0 = 0),\n",
       "             ('_C32',\n",
       "              -1*byproduct_copper_dust + 0.2*recipe_centrifuge_sluice_juice + 0.0 = 0),\n",
       "             ('_C33', -1*in_sub_quicklime + 1*in_switch_quicklime + 0 >= 0),\n",
       "             ('_C34',\n",
       "              -1*byproduct_quicklime + -10000.0*in_sub_quicklime + 10000.0*in_switch_quicklime + 2*recipe_centrifuge_bauxite_slag + 2*recipe_lcr_calcite + -4*recipe_mixer_purified_bauxite + 0.0 = 0),\n",
       "             ('_C35',\n",
       "              -1*in_sub_bauxite_slurry + 1*in_switch_bauxite_slurry + 0 >= 0),\n",
       "             ('_C36',\n",
       "              -1*byproduct_bauxite_slurry + -10000.0*in_sub_bauxite_slurry + 10000.0*in_switch_bauxite_slurry + 8*recipe_mixer_purified_bauxite + -32*recipe_oc_steam + 0.0 = 0),\n",
       "             ('_C37',\n",
       "              -1*byproduct_alumina + 8*recipe_lcr_carbon_dioxide + -10 = 0),\n",
       "             ('_C38',\n",
       "              -1*in_sub_sodium_dust + 1*in_switch_sodium_dust + 0 >= 0),\n",
       "             ('_C39',\n",
       "              -1*byproduct_sodium_dust + -10000.0*in_sub_sodium_dust + 10000.0*in_switch_sodium_dust + 2*recipe_electrolyzer_sodium_carbonate + -1*recipe_lcr_sodium_dust + 0.0 = 0),\n",
       "             ('_C40',\n",
       "              -1*byproduct_iron_dust + 8*recipe_centrifuge_bauxite_slag + 0.4*recipe_centrifuge_sluice_juice + 0.0 = 0),\n",
       "             ('_C41',\n",
       "              -1*byproduct_tin_dust + 0.2*recipe_centrifuge_sluice_juice + 0.0 = 0),\n",
       "             ('_C42', -1*in_sub_steam + 1*in_switch_steam + 0 >= 0),\n",
       "             ('_C43',\n",
       "              -1*byproduct_steam + -10000.0*in_sub_steam + 10000.0*in_switch_steam + -2*recipe_oc_steam + 0.0 = 0),\n",
       "             ('_C44',\n",
       "              -1*in_sub_aluminium_hydroxide + 1*in_switch_aluminium_hydroxide + 0 >= 0),\n",
       "             ('_C45',\n",
       "              -1*byproduct_aluminium_hydroxide + -10000.0*in_sub_aluminium_hydroxide + 10000.0*in_switch_aluminium_hydroxide + -1*recipe_lcr_carbon_dioxide + 7*recipe_lcr_sodium_aluminate + 0.0 = 0)])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method LpProblem.variables of gtnh_flow_lp_solver:\n",
       "MINIMIZE\n",
       "3614751562500.0*byproduct_alumina + 3614751562500.0*byproduct_aluminium_dust + 3614751562500.0*byproduct_aluminium_hydroxide + -975.0*byproduct_antimony_dust + 3614751562500.0*byproduct_bauxite_slag + 3614751562500.0*byproduct_bauxite_slurry + 3614751562500.0*byproduct_calcite + 3614751562500.0*byproduct_carbon_dioxide + -975.0*byproduct_carbon_dust + -975.0*byproduct_copper_dust + -975.0*byproduct_gallium + 3614751562500.0*byproduct_heated_bauxite_slurry + -975.0*byproduct_hydrogen + -975.0*byproduct_iron_dust + -975.0*byproduct_nickel_dust + -975.0*byproduct_oxygen + 3614751562500.0*byproduct_purified_bauxite + 3614751562500.0*byproduct_quicklime + -975.0*byproduct_rutile + -975.0*byproduct_silicon_dioxide + 3614751562500.0*byproduct_sluice_juice + 3614751562500.0*byproduct_sodium_aluminate + 3614751562500.0*byproduct_sodium_carbonate + 3614751562500.0*byproduct_sodium_dust + 3614751562500.0*byproduct_sodium_hydroxide + 3614751562500.0*byproduct_steam + -975.0*byproduct_stone_dust + -975.0*byproduct_tin_dust + 3614751562500.0*byproduct_water + -926859375.0*in_sub_aluminium_dust + -926859375.0*in_sub_aluminium_hydroxide + -926859375.0*in_sub_bauxite_slag + -926859375.0*in_sub_bauxite_slurry + -926859375.0*in_sub_calcite + -926859375.0*in_sub_carbon_dioxide + -926859375.0*in_sub_heated_bauxite_slurry + -926859375.0*in_sub_purified_bauxite + -926859375.0*in_sub_quicklime + -926859375.0*in_sub_sluice_juice + -926859375.0*in_sub_sodium_aluminate + -926859375.0*in_sub_sodium_carbonate + -926859375.0*in_sub_sodium_dust + -926859375.0*in_sub_sodium_hydroxide + -926859375.0*in_sub_steam + -926859375.0*in_sub_water + 1807375781250.0*in_switch_aluminium_dust + 1807375781250.0*in_switch_aluminium_hydroxide + 1807375781250.0*in_switch_bauxite_slag + 1807375781250.0*in_switch_bauxite_slurry + 1807375781250.0*in_switch_calcite + 1807375781250.0*in_switch_carbon_dioxide + 1807375781250.0*in_switch_heated_bauxite_slurry + 1807375781250.0*in_switch_purified_bauxite + 1807375781250.0*in_switch_quicklime + 1807375781250.0*in_switch_sluice_juice + 1807375781250.0*in_switch_sodium_aluminate + 1807375781250.0*in_switch_sodium_carbonate + 1807375781250.0*in_switch_sodium_dust + 1807375781250.0*in_switch_sodium_hydroxide + 1807375781250.0*in_switch_steam + 1807375781250.0*in_switch_water + 1.0*recipe_centrifuge_bauxite_slag + 1.0*recipe_centrifuge_sluice_juice + 1.0*recipe_electrolyzer_sodium_carbonate + 1.0*recipe_lcr_aluminium_dust + 1.0*recipe_lcr_calcite + 1.0*recipe_lcr_carbon_dioxide + 1.0*recipe_lcr_sodium_aluminate + 1.0*recipe_lcr_sodium_dust + 1.0*recipe_mixer_purified_bauxite + 1.0*recipe_oc_steam + 0.0\n",
       "SUBJECT TO\n",
       "_C1: - in_sub_heated_bauxite_slurry + in_switch_heated_bauxite_slurry >= 0\n",
       "\n",
       "_C2: - byproduct_heated_bauxite_slurry - 10000 in_sub_heated_bauxite_slurry\n",
       " + 10000 in_switch_heated_bauxite_slurry - 32 recipe_lcr_carbon_dioxide\n",
       " + 32 recipe_oc_steam = 0\n",
       "\n",
       "_C3: - byproduct_nickel_dust + 0.2 recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C4: - byproduct_antimony_dust + 0.2 recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C5: - in_sub_calcite + in_switch_calcite >= 0\n",
       "\n",
       "_C6: - byproduct_calcite - 10000 in_sub_calcite + 10000 in_switch_calcite\n",
       " - 5 recipe_lcr_calcite + 10 recipe_lcr_carbon_dioxide = 0\n",
       "\n",
       "_C7: - in_sub_sluice_juice + in_switch_sluice_juice >= 0\n",
       "\n",
       "_C8: - byproduct_sluice_juice - 10000 in_sub_sluice_juice\n",
       " + 10000 in_switch_sluice_juice - recipe_centrifuge_sluice_juice\n",
       " + 5 recipe_lcr_carbon_dioxide = 0\n",
       "\n",
       "_C9: - in_sub_sodium_carbonate + in_switch_sodium_carbonate >= 0\n",
       "\n",
       "_C10: - byproduct_sodium_carbonate - 10000 in_sub_sodium_carbonate\n",
       " + 10000 in_switch_sodium_carbonate - 6 recipe_electrolyzer_sodium_carbonate\n",
       " + 9 recipe_lcr_carbon_dioxide = 0\n",
       "\n",
       "_C11: - in_sub_sodium_aluminate + in_switch_sodium_aluminate >= 0\n",
       "\n",
       "_C12: - byproduct_sodium_aluminate - 10000 in_sub_sodium_aluminate\n",
       " + 10000 in_switch_sodium_aluminate + 16 recipe_lcr_aluminium_dust\n",
       " - recipe_lcr_sodium_aluminate = 0\n",
       "\n",
       "_C13: - in_sub_water + in_switch_water >= 0\n",
       "\n",
       "_C14: - byproduct_water - 10000 in_sub_water + 10000 in_switch_water\n",
       " - 16 recipe_lcr_aluminium_dust - 2 recipe_lcr_sodium_aluminate\n",
       " - recipe_lcr_sodium_dust - 5 recipe_mixer_purified_bauxite = 0\n",
       "\n",
       "_C15: - in_sub_bauxite_slag + in_switch_bauxite_slag >= 0\n",
       "\n",
       "_C16: - byproduct_bauxite_slag - 10000 in_sub_bauxite_slag\n",
       " + 10000 in_switch_bauxite_slag - recipe_centrifuge_bauxite_slag\n",
       " + 16 recipe_lcr_carbon_dioxide = 0\n",
       "\n",
       "_C17: - byproduct_oxygen + 3 recipe_electrolyzer_sodium_carbonate = 0\n",
       "\n",
       "_C18: - in_sub_carbon_dioxide + in_switch_carbon_dioxide >= 0\n",
       "\n",
       "_C19: - byproduct_carbon_dioxide - 10000 in_sub_carbon_dioxide\n",
       " + 10000 in_switch_carbon_dioxide + recipe_lcr_calcite\n",
       " - 5 recipe_lcr_carbon_dioxide = 0\n",
       "\n",
       "_C20: - byproduct_gallium + 3 recipe_centrifuge_bauxite_slag = 0\n",
       "\n",
       "_C21: - byproduct_hydrogen + 48 recipe_lcr_aluminium_dust\n",
       " + recipe_lcr_sodium_dust = 0\n",
       "\n",
       "_C22: - byproduct_rutile + recipe_centrifuge_bauxite_slag = 0\n",
       "\n",
       "_C23: - byproduct_silicon_dioxide + 9 recipe_centrifuge_bauxite_slag = 0\n",
       "\n",
       "_C24: - in_sub_sodium_hydroxide + in_switch_sodium_hydroxide >= 0\n",
       "\n",
       "_C25: - byproduct_sodium_hydroxide - 10000 in_sub_sodium_hydroxide\n",
       " + 10000 in_switch_sodium_hydroxide - 16 recipe_lcr_aluminium_dust\n",
       " + recipe_lcr_sodium_aluminate + recipe_lcr_sodium_dust\n",
       " - 3 recipe_mixer_purified_bauxite = 0\n",
       "\n",
       "_C26: - byproduct_stone_dust + recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C27: - in_sub_aluminium_dust + in_switch_aluminium_dust >= 0\n",
       "\n",
       "_C28: - byproduct_aluminium_dust - 10000 in_sub_aluminium_dust\n",
       " + 10000 in_switch_aluminium_dust - 16 recipe_lcr_aluminium_dust = 0\n",
       "\n",
       "_C29: - in_sub_purified_bauxite + in_switch_purified_bauxite >= 0\n",
       "\n",
       "_C30: - byproduct_purified_bauxite - 10000 in_sub_purified_bauxite\n",
       " + 10000 in_switch_purified_bauxite - 32 recipe_mixer_purified_bauxite = 0\n",
       "\n",
       "_C31: - byproduct_carbon_dust + recipe_electrolyzer_sodium_carbonate = 0\n",
       "\n",
       "_C32: - byproduct_copper_dust + 0.2 recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C33: - in_sub_quicklime + in_switch_quicklime >= 0\n",
       "\n",
       "_C34: - byproduct_quicklime - 10000 in_sub_quicklime\n",
       " + 10000 in_switch_quicklime + 2 recipe_centrifuge_bauxite_slag\n",
       " + 2 recipe_lcr_calcite - 4 recipe_mixer_purified_bauxite = 0\n",
       "\n",
       "_C35: - in_sub_bauxite_slurry + in_switch_bauxite_slurry >= 0\n",
       "\n",
       "_C36: - byproduct_bauxite_slurry - 10000 in_sub_bauxite_slurry\n",
       " + 10000 in_switch_bauxite_slurry + 8 recipe_mixer_purified_bauxite\n",
       " - 32 recipe_oc_steam = 0\n",
       "\n",
       "_C37: - byproduct_alumina + 8 recipe_lcr_carbon_dioxide = 10\n",
       "\n",
       "_C38: - in_sub_sodium_dust + in_switch_sodium_dust >= 0\n",
       "\n",
       "_C39: - byproduct_sodium_dust - 10000 in_sub_sodium_dust\n",
       " + 10000 in_switch_sodium_dust + 2 recipe_electrolyzer_sodium_carbonate\n",
       " - recipe_lcr_sodium_dust = 0\n",
       "\n",
       "_C40: - byproduct_iron_dust + 8 recipe_centrifuge_bauxite_slag\n",
       " + 0.4 recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C41: - byproduct_tin_dust + 0.2 recipe_centrifuge_sluice_juice = 0\n",
       "\n",
       "_C42: - in_sub_steam + in_switch_steam >= 0\n",
       "\n",
       "_C43: - byproduct_steam - 10000 in_sub_steam + 10000 in_switch_steam\n",
       " - 2 recipe_oc_steam = 0\n",
       "\n",
       "_C44: - in_sub_aluminium_hydroxide + in_switch_aluminium_hydroxide >= 0\n",
       "\n",
       "_C45: - byproduct_aluminium_hydroxide - 10000 in_sub_aluminium_hydroxide\n",
       " + 10000 in_switch_aluminium_hydroxide - recipe_lcr_carbon_dioxide\n",
       " + 7 recipe_lcr_sodium_aluminate = 0\n",
       "\n",
       "VARIABLES\n",
       "byproduct_alumina Continuous\n",
       "byproduct_aluminium_dust Continuous\n",
       "byproduct_aluminium_hydroxide Continuous\n",
       "byproduct_antimony_dust Continuous\n",
       "byproduct_bauxite_slag Continuous\n",
       "byproduct_bauxite_slurry Continuous\n",
       "byproduct_calcite Continuous\n",
       "byproduct_carbon_dioxide Continuous\n",
       "byproduct_carbon_dust Continuous\n",
       "byproduct_copper_dust Continuous\n",
       "byproduct_gallium Continuous\n",
       "byproduct_heated_bauxite_slurry Continuous\n",
       "byproduct_hydrogen Continuous\n",
       "byproduct_iron_dust Continuous\n",
       "byproduct_nickel_dust Continuous\n",
       "byproduct_oxygen Continuous\n",
       "byproduct_purified_bauxite Continuous\n",
       "byproduct_quicklime Continuous\n",
       "byproduct_rutile Continuous\n",
       "byproduct_silicon_dioxide Continuous\n",
       "byproduct_sluice_juice Continuous\n",
       "byproduct_sodium_aluminate Continuous\n",
       "byproduct_sodium_carbonate Continuous\n",
       "byproduct_sodium_dust Continuous\n",
       "byproduct_sodium_hydroxide Continuous\n",
       "byproduct_steam Continuous\n",
       "byproduct_stone_dust Continuous\n",
       "byproduct_tin_dust Continuous\n",
       "byproduct_water Continuous\n",
       "in_sub_aluminium_dust <= 1 Continuous\n",
       "in_sub_aluminium_hydroxide <= 1 Continuous\n",
       "in_sub_bauxite_slag <= 1 Continuous\n",
       "in_sub_bauxite_slurry <= 1 Continuous\n",
       "in_sub_calcite <= 1 Continuous\n",
       "in_sub_carbon_dioxide <= 1 Continuous\n",
       "in_sub_heated_bauxite_slurry <= 1 Continuous\n",
       "in_sub_purified_bauxite <= 1 Continuous\n",
       "in_sub_quicklime <= 1 Continuous\n",
       "in_sub_sluice_juice <= 1 Continuous\n",
       "in_sub_sodium_aluminate <= 1 Continuous\n",
       "in_sub_sodium_carbonate <= 1 Continuous\n",
       "in_sub_sodium_dust <= 1 Continuous\n",
       "in_sub_sodium_hydroxide <= 1 Continuous\n",
       "in_sub_steam <= 1 Continuous\n",
       "in_sub_water <= 1 Continuous\n",
       "0 <= in_switch_aluminium_dust <= 1 Integer\n",
       "0 <= in_switch_aluminium_hydroxide <= 1 Integer\n",
       "0 <= in_switch_bauxite_slag <= 1 Integer\n",
       "0 <= in_switch_bauxite_slurry <= 1 Integer\n",
       "0 <= in_switch_calcite <= 1 Integer\n",
       "0 <= in_switch_carbon_dioxide <= 1 Integer\n",
       "0 <= in_switch_heated_bauxite_slurry <= 1 Integer\n",
       "0 <= in_switch_purified_bauxite <= 1 Integer\n",
       "0 <= in_switch_quicklime <= 1 Integer\n",
       "0 <= in_switch_sluice_juice <= 1 Integer\n",
       "0 <= in_switch_sodium_aluminate <= 1 Integer\n",
       "0 <= in_switch_sodium_carbonate <= 1 Integer\n",
       "0 <= in_switch_sodium_dust <= 1 Integer\n",
       "0 <= in_switch_sodium_hydroxide <= 1 Integer\n",
       "0 <= in_switch_steam <= 1 Integer\n",
       "0 <= in_switch_water <= 1 Integer\n",
       "recipe_centrifuge_bauxite_slag Continuous\n",
       "recipe_centrifuge_sluice_juice Continuous\n",
       "recipe_electrolyzer_sodium_carbonate Continuous\n",
       "recipe_lcr_aluminium_dust Continuous\n",
       "recipe_lcr_calcite Continuous\n",
       "recipe_lcr_carbon_dioxide Continuous\n",
       "recipe_lcr_sodium_aluminate Continuous\n",
       "recipe_lcr_sodium_dust Continuous\n",
       "recipe_mixer_purified_bauxite Continuous\n",
       "recipe_oc_steam Continuous\n",
       ">"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problem.variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks like it's working! Next on the chopping block is what I'm calling \"Matrix Normalization\" \n",
    "# ... although I'm not even sure that's the right name.\n",
    "# The idea is to scale both item and recipe vectors so that the largest value in each is 1, \n",
    "# ... AND we minimize the ratio between the largest and smallest values in the matrix (which we use as the priority ratio)\n",
    "# This should make the LP solver more numerically stable and less likely to run into precision issues.\n",
    "# It will also help with the \"1 trillion or so ought to do\" problem, as we can use a smaller BIG_NUMBER,\n",
    "# and help put items in the same priority level on the same-ish scale.\n",
    "\n",
    "# The rows can be scaled for free - divide the row (all ingredients) by the largest value in the row.\n",
    "# The challenge is finding a scale factor for the *columns* which minimizes the ratio between the largest and smallest\n",
    "# ... values in the *matrix*.\n",
    "\n",
    "# One way to formulate this in LP would be to minimize the difference between\n",
    "# ... the largest and smallest values in the values, which are themselves variables that are solved for.\n",
    "\n",
    "# I'mma ask ChatGPT for this one... oh boy did GPT deliver. I love this stuff.\n",
    "\n",
    "# Here's its write-up:\n",
    "# This approach aims to scale a matrix such that each column is adjusted by a \n",
    "# scaling factor to ensure numerical stability in linear programming (LP) solvers. \n",
    "# First, each vector (row) in the matrix is normalized so that the largest value in \n",
    "# each vector becomes 1. Using the PuLP library, an optimization problem is then set \n",
    "# up with the objective of minimizing the difference between the maximum and minimum \n",
    "# scaled values in the matrix. The variables in this optimization problem are the \n",
    "# scaling factors for each column. Constraints are added to ensure that each element \n",
    "# in the matrix, when scaled, lies between the defined maximum and minimum values. \n",
    "# The optimization problem is solved to determine the optimal scaling factors, \n",
    "# which are then applied to the normalized matrix. \n",
    "# This process ensures the matrix values are balanced and the ratio between the \n",
    "# largest and smallest values is minimized, enhancing the numerical stability of \n",
    "# LP solvers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe Vectors [('centrifuge_ashes', [5.4, -36, 0, 1, 4, 0.45, 0, 11.52, 2]), ('electrolyzer_quicklime_dust', [0, 0, 1, 0, 0, 0, 1000, -2, 0])]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(5.4, 0),\n",
       " (-36, 0),\n",
       " (0, 1),\n",
       " (1, 0),\n",
       " (4, 0),\n",
       " (0.45, 0),\n",
       " (0, 1000),\n",
       " (11.52, -2),\n",
       " (2, 0)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getIngMatrix(recipes):\n",
    "    inputs = set()\n",
    "    explicit_inputs = set()\n",
    "    outputs = set()\n",
    "    targets = {}\n",
    "    # Just use indices to identify recipes here\n",
    "    for recipe, io in enumerate(recipes):\n",
    "        for ing in io.I:\n",
    "            ing_name = stripBrackets(ing.name)\n",
    "            inputs.add(ing_name)\n",
    "        for out in io.O:\n",
    "            out_name = stripBrackets(out.name)\n",
    "            outputs.add(out_name)\n",
    "        if hasattr(io, \"cost\"):\n",
    "            for explicit_input in getattr(io, \"cost\"):\n",
    "                explicit_inputs.add(explicit_input)\n",
    "        if hasattr(io, \"target\"):\n",
    "            for target, quant in getattr(io, \"target\").items():\n",
    "                targets[target] = quant\n",
    "                \n",
    "    if not all(target in outputs for target in targets): \n",
    "        raise RuntimeError(\"Encountered target which is never an output (likely a spelling mistake). targets: \" +str(targets))\n",
    "    if not all(cost in inputs for cost in explicit_inputs):\n",
    "        raise RuntimeError(\"Encountered cost/explicit input which is never an input (likely a spelling mistake). costs: \" +str(explicit_inputs))\n",
    "    \n",
    "    variables = list(inputs | outputs) # Make it a list because order matters\n",
    "    additional_inputs = inputs - explicit_inputs\n",
    "    # print(additional_inputs)\n",
    "    # Outputs that are only ever outputs (and not targets) are likely desired.        \n",
    "    desired_byproducts = (outputs - inputs) - set(targets.keys())\n",
    "    minimized_byproducts = set(variables) - desired_byproducts\n",
    "    \n",
    "    recipe_vectors = []\n",
    "    variable_indices = {var: i for i, var in enumerate(variables)}\n",
    "    # print(variable_indices)\n",
    "    for recipe in recipes:\n",
    "        vector = [0] * len(variables)\n",
    "        for ing in recipe.I:\n",
    "            vector[variable_indices[stripBrackets(ing.name)]] = -1 * ing.quant\n",
    "        for out in recipe.O:\n",
    "            vector[variable_indices[stripBrackets(out.name)]] = out.quant\n",
    "        recipe_vectors.append(vector)\n",
    "    recipe_names = genRecipeNames(recipes)\n",
    "    print(\"Recipe Vectors\", list(zip(recipe_names, recipe_vectors)))\n",
    "    ing_vectors = list(zip(*recipe_vectors)) # Transpose (constraints are per-item, not per-recipe)\n",
    "    return ing_vectors\n",
    "    # target_vector = [targets.get(var, 0) for var in variables]\n",
    "    # row_scales,col_scales, scaled_matrix = scale_matrix(ing_vectors)\n",
    "    \n",
    "    # print(list(zip(variables, row_scales)))\n",
    "    # print(list(zip(recipe_names, col_scales)))\n",
    "    # print(col_scales)\n",
    "    # print()\n",
    "    # # for row in scaled_matrix: print(row)\n",
    "    # import csv\n",
    "    # with open(\"test_mat.csv\", \"w\") as f:\n",
    "    #     csv.writer(f).writerows(scaled_matrix)\n",
    "    # print(value(problem.objective))\n",
    "    # print(list(zip(scaled_matrix)))\n",
    "\n",
    "getIngMatrix(recipesFromConfig(\"renewables/calcium/ashes.yaml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9000.0, 0.0, 0.0]\n",
      "[1000.0, -9000.0, 0.0]\n",
      "[-592.10526, -5328.947340000001, 562.499997]\n",
      "[0.0, 9000.0, -562.5]\n",
      "[0.0, 9000.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# ... and here's the routine:\n",
    "import pulp\n",
    "\n",
    "# Function to normalize a matrix with the added constraint\n",
    "def pulp_scale_matrix(matrix):\n",
    "    \n",
    "    num_rows = len(matrix)\n",
    "    num_cols = len(matrix[0])\n",
    "   \n",
    "    # Create a PuLP problem instance\n",
    "    prob = pulp.LpProblem(\"MinimizeMatrixRatio\", pulp.LpMinimize)\n",
    "    \n",
    "    # Variables: scaling factors for each row and column\n",
    "    row_scale_factors = [pulp.LpVariable(f\"rs_{i}\", lowBound=1) for i in range(num_rows)]\n",
    "    \n",
    "    # Constraints and objective function\n",
    "    max_val = pulp.LpVariable(\"max_val\", lowBound=0)\n",
    "    min_val = pulp.LpVariable(\"min_val\", lowBound=0)\n",
    "    \n",
    "    # Define constraints and objective for each element in the matrix\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if abs(matrix[i][j]) > 0:\n",
    "                scaled_value = abs(matrix[i][j]) * row_scale_factors[i]\n",
    "                prob += max_val >= scaled_value\n",
    "                prob += min_val <= scaled_value\n",
    "    \n",
    "    # Objective: min (max_val - min_val)\n",
    "    prob += max_val - min_val\n",
    "    \n",
    "    # Solve the problem\n",
    "    prob.solve()\n",
    "    \n",
    "    # Extract the scale factors\n",
    "    row_scale_factors = [scale_factor.varValue for scale_factor in row_scale_factors]\n",
    "    \n",
    "    # Apply the scaling factors to the normalized matrix\n",
    "    scaled_matrix = [[matrix[i][j] * row_scale_factors[i] for j in range(num_cols)] for i in range(num_rows)]\n",
    "    \n",
    "    return row_scale_factors, scaled_matrix\n",
    "    # print(value(min_val), value(max_val))\n",
    "    # return row_scales, col_scales, scaled_matrix\n",
    "\n",
    "# Example usage\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    "\n",
    "pulp_row_scales, pulp_matrix = pulp_scale_matrix(pall_loop)\n",
    "for row in pulp_matrix:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solve time 8.18e-05\n",
      "Original Ratio 9473.684210526317\n",
      "LP Ratio 16.000000085333333\n",
      "QP Ratio 1.2995725793517645\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.70937433,  0.        ,  0.        ],\n",
       "       [ 4.91960199, -4.50813025,  0.        ],\n",
       "       [-4.50813025, -4.1310737 ,  5.3686301 ],\n",
       "       [ 0.        ,  5.3686301 , -4.1310737 ],\n",
       "       [ 0.        ,  4.70937433,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.0e+03,  0.0e+00,  0.0e+00],\n",
       "       [ 1.0e+03, -9.0e+03,  0.0e+00],\n",
       "       [-1.0e+00, -9.0e+00,  9.5e-01],\n",
       "       [ 0.0e+00,  1.6e+01, -1.0e+00],\n",
       "       [ 0.0e+00,  2.0e+00,  0.0e+00]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I think solving jointly for both row and column scale factors will yield a better ratio, but that requires\n",
    "# some quadratic solving. I think the cvxpy library may do the trick, but I want to confirm that the \n",
    "# ratio improvement is actually good enough for adding the dependency (or switching to it from pulp)\n",
    "\n",
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "def qp_scale_matrix(matrix):\n",
    "    num_rows = len(matrix)\n",
    "    num_cols = len(matrix[0])\n",
    "    \n",
    "    # Variables: scaling factors for each row and column\n",
    "    row_scale_factors = cp.Variable(num_rows, pos=True)\n",
    "    col_scale_factors = cp.Variable(num_cols, pos=True)\n",
    "    \n",
    "    # Constraints and objective function\n",
    "    constraints = []\n",
    "    max_val = cp.Variable(pos=True)\n",
    "    min_val = cp.Variable(pos=True)\n",
    "    \n",
    "    # Define constraints and objective for each element in the matrix\n",
    "    for i in range(num_rows):\n",
    "        for j in range(num_cols):\n",
    "            if abs(matrix[i][j]) > 0:\n",
    "                scaled_value = abs(matrix[i][j]) * row_scale_factors[i] * col_scale_factors[j]\n",
    "                constraints.append(max_val >= scaled_value)\n",
    "                constraints.append(min_val <= scaled_value)\n",
    "    \n",
    "    # Objective: min (max_val - min_val)\n",
    "    objective = cp.Minimize(max_val / min_val)\n",
    "    \n",
    "    # Create the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "    \n",
    "    # Solve the problem\n",
    "    problem.solve(gp=True)\n",
    "    print(\"Solve time\", problem.solver_stats.solve_time)\n",
    "    \n",
    "    # Extract the scale factors\n",
    "    row_scale_factors = row_scale_factors.value\n",
    "    col_scale_factors = col_scale_factors.value\n",
    "    \n",
    "    # Apply the scaling factors to the normalized matrix\n",
    "    scaled_matrix = np.multiply(matrix, np.outer(row_scale_factors, col_scale_factors))\n",
    "    \n",
    "    return row_scale_factors, col_scale_factors, scaled_matrix\n",
    "\n",
    "\n",
    "def ratio_test(matrix):\n",
    "    pulp_row_scales, pulp_matrix = pulp_scale_matrix(matrix)\n",
    "    pulp_matrix = np.array(pulp_matrix)\n",
    "    qp_row_scales, qp_col_scales, qp_matrix = qp_scale_matrix(matrix)\n",
    "    og_nonzero_abs = np.abs(matrix[np.nonzero(matrix)])\n",
    "    pulp_nonzero_abs = np.abs(pulp_matrix[np.nonzero(pulp_matrix)])\n",
    "    qp_nonzero_abs = np.abs(qp_matrix[np.nonzero(np.array(qp_matrix))])\n",
    "    print(\"Original Ratio\", np.max(og_nonzero_abs) / np.min(og_nonzero_abs))\n",
    "    print(\"LP Ratio\", np.max(pulp_nonzero_abs) / np.min(pulp_nonzero_abs))\n",
    "    print(\"QP Ratio\", np.max(qp_nonzero_abs) / np.min(qp_nonzero_abs))\n",
    "    return qp_matrix\n",
    "display(ratio_test(np.array(pall_loop)))\n",
    "display(np.array(pall_loop))\n",
    "# That is dramatic... but I want to make sure I haven't optimized too close to the sun.\n",
    "# After doing this, does the LP solution (after getting un-scaled) still work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
