{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PuLP dependency to seriously simplify setting up LP problem. It's just a wrapper to help set things up,\n",
    "#  but it does come with a built-in solver (which we will also use)\n",
    "from pulp import LpVariable, LpProblem, LpMinimize, lpDot, LpStatus, value\n",
    "import numpy as np\n",
    "\n",
    "from src.graph import Graph\n",
    "from src.graph._preProcessing import connectGraph, removeBackEdges\n",
    "from src.data.basicTypes import Ingredient, IngredientCollection, Recipe\n",
    "from factory_graph import ProgramContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LPSolver:\n",
    "    def __init__(self, graph):\n",
    "        self.graph = graph\n",
    "        self.variables = []\n",
    "        # self.variable_idx_counter = 0 # Autogen current \"head\" index for variable number\n",
    "        # self.system = []\n",
    "        self.solved_vars = None # Result from linear solver\n",
    "\n",
    "        self.lookup = {} # (machine, product, direction, multi_idx) -> variable index\n",
    "        self.edge_from_perspective_to_index = {} # (edge, machine_id) -> variable index\n",
    "\n",
    "def graphPreProcessing(self):\n",
    "    connectGraph(self)\n",
    "    # if not self.graph_config.get('KEEP_BACK_EDGES', False):\n",
    "    #     removeBackEdges(self)\n",
    "    Graph.createAdjacencyList(self)\n",
    "\n",
    "def linearProgrammingSolver(self: ProgramContext, project_name: str, recipes: list[Recipe], graph_config: dict):\n",
    "    g = Graph(project_name, recipes, self, graph_config=graph_config)\n",
    "    self._graph = g # For test access\n",
    "    graphPreProcessing(g)\n",
    "    print(g.adj)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<function createAdjacencyList.<locals>.<lambda> at 0x000001F4E50179C0>, {'source': defaultdict(<class 'list'>, {'O': [('source', '0', 'pams fish')]}), '0': defaultdict(<class 'list'>, {'I': [('source', '0', 'pams fish')], 'O': [('0', '1', 'methane')]}), '1': defaultdict(<class 'list'>, {'I': [('0', '1', 'methane')], 'O': [('1', 'sink', 'biogas')]}), 'sink': defaultdict(<class 'list'>, {'I': [('1', 'sink', 'biogas')]})})\n"
     ]
    }
   ],
   "source": [
    "context = ProgramContext()\n",
    "\n",
    "context.graph_gen = linearProgrammingSolver # Override solver\n",
    "context.generate_one(\"power/fish/methane.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is me figuring out edge cases.\n",
    "\n",
    "\"\"\"\n",
    "- m: centrifuge\n",
    "  tier: LV\n",
    "  I:\n",
    "    pams fish: 1\n",
    "  O:\n",
    "    methane: 96\n",
    "  eut: 5\n",
    "  dur: 19\n",
    "  number: 1\n",
    "  cost_priority:\n",
    "    pams fish: 1\n",
    "  # target:\n",
    "  #   # methane: 250\n",
    "  #   pams fish: 1\n",
    "- m: distillery\n",
    "  tier: LV\n",
    "  I:\n",
    "    methane: 125\n",
    "  O:\n",
    "    biogas: 375\n",
    "  eut: 7\n",
    "  dur: 1\n",
    "\"\"\"\n",
    "\n",
    "#  \n",
    "\n",
    "problem = LpProblem(\"test\", LpMinimize)\n",
    "cost_inputs = [\"pams fish\"]\n",
    "recipe_vars = [\"pams fish\", \"methane\"]\n",
    "items = [\"pams fish\", \"methane\", \"biogas\"]\n",
    "target_vector = [0,0,1000]\n",
    "recipe_vectors = {\n",
    "  \"fuge\": [-1, 96, 0],\n",
    "  \"dist\": [0, -125, 375]\n",
    "}\n",
    "# How do you figure out which variables should be inputs?\n",
    "input_vectors = {\n",
    "  \"fish_in\": [1, 0, 0],\n",
    "}\n",
    "# rec_mat = np.array(list(recipe_vectors.values())+ list(input_vectors.values()))\n",
    "# display(rec_mat)\n",
    "# rec_mat.transpose()\n",
    "all_vectors = recipe_vectors.copy()\n",
    "all_vectors.update(input_vectors)\n",
    "# Item constraints are transpose of values of constraint vectors (all vectors)\n",
    "item_constraints = np.array(list(all_vectors.values())).transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Optimal'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# problem.variables()\n",
    "# Create variables\n",
    "recipe_vars = LpVariable.dicts(\"rec\", all_vectors.keys(), lowBound=0, cat=\"Continuous\")\n",
    "\n",
    "# Add objective\n",
    "problem += recipe_vars[\"fish_in\"]\n",
    "# Add constraints\n",
    "for item_constraint_vec, target in zip(item_constraints, target_vector):\n",
    "    problem += lpDot(recipe_vars.values(), item_constraint_vec) >= target\n",
    "# problem += lpDot(x.values(), target_vector) >= 0\n",
    "\n",
    "problem.solve()\n",
    "LpStatus[problem.status]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec_dist = 2.6666667\n",
      "rec_fish_in = 3.4722222\n",
      "rec_fuge = 3.4722222\n"
     ]
    }
   ],
   "source": [
    "for v in problem.variables():\n",
    "    print(v.name, \"=\", v.varValue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0, 0],\n",
       " [0, 1, 0],\n",
       " [0, 0, 1],\n",
       " [0, 0, 0],\n",
       " [0, 0, 0]]),\n",
       " (0, 1, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# That works, now let's mess around with ways to identify input candidates\n",
    "# Cases that need to be inputs are useful to report the user, \n",
    "# but we want to find \"eliminated\" variables as described by https://github.com/ClaudeMetz/FactoryPlanner/blob/master/modfiles/backend/calculation/matrix_engine.lua\n",
    "# - that is, variables that are net-zero after all loops/etc and don't need to be system inputs.\n",
    "\n",
    "# I'm theorizing that the \"eliminated\" variables might be findable via the reduced row echelon form of the matrix.\n",
    "\n",
    "from sympy import Matrix\n",
    "# m = Matrix(np.hstack([item_constraints, np.array(target_vector).reshape(-1,1)]))\n",
    "# m.rref()\n",
    "\n",
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    " \n",
    "positive_cost_cycle = Matrix(pall_loop)\n",
    " \n",
    "positive_cost_cycle.rref()\n",
    "#  Oh yeah, duh, rref on an over-defined matrix. Uhhhh\n",
    "# This matrix converts recipe executions to items produced, \n",
    "# and solving it finds necessary recipes executions/unit time to produce desired items\n",
    "# We're looking for input-item-to-output item conversions. How do we find those?\n",
    "# - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [  -0.0123427693881819,     0.999920219926959, -0.00266637715277894],\n",
       " [    0.999921784104044,     0.012337578452739, -0.00197762613328934],\n",
       " [ 0.000975236276396803,   0.00201218158793192,    0.688745946762978],\n",
       " [ -0.00175569605886587,  -0.00179957317684196,   -0.724995172566176],\n",
       " [-0.000219462003270191, -0.000224946177417711,   1.0320007302374e-6]]),\n",
       " Matrix([\n",
       " [9056.0851669197,                0,                0],\n",
       " [              0, 993.812582692507,                0],\n",
       " [              0,                0, 1.37930382200068]]),\n",
       " Matrix([\n",
       " [  0.111777170775024,   -0.99373329625207,  3.6777441977233e-6],\n",
       " [ -0.993733296258832,  -0.111777170773151, 7.11721275761968e-7],\n",
       " [2.96173288126787e-7, 3.73425105498543e-6,   0.999999999992984]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cost_cycle.singular_value_decomposition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle \\left[\\begin{matrix}1000000 & -1000000 & 1000 & 0 & 0\\\\-1000000 & 82000000 & 80000 & -144000 & -18000\\\\1000 & 80000 & 82.9025 & -144.95 & -18\\\\0 & -144000 & -144.95 & 257 & 32\\\\0 & -18000 & -18 & 32 & 4\\end{matrix}\\right]$"
      ],
      "text/plain": [
       "Matrix([\n",
       "[ 1000000, -1000000,    1000,       0,      0],\n",
       "[-1000000, 82000000,   80000, -144000, -18000],\n",
       "[    1000,    80000, 82.9025, -144.95,    -18],\n",
       "[       0,  -144000, -144.95,     257,     32],\n",
       "[       0,   -18000,     -18,      32,      4]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_cost_cycle * positive_cost_cycle.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Matrix([\n",
       " [1, 0],\n",
       " [0, 1]]),\n",
       " (0, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simpler_pos_cost = Matrix([\n",
    "    [-1, 2],\n",
    "    [0.25, -1]\n",
    "])\n",
    "simpler_pos_cost.rref()\n",
    "# I don't think this is going to work for determining which should be inputs, but I think I can figure it out using LP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    "target_vector = [0, 0, 0, 0, 10]\n",
    "\n",
    "# New theory: for anything that is ever an input, make an input vector, but tell LP to minimize number used\n",
    "# Possible upgrade: seek to maximize earliness of inputs in a topological sort or derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well poop.\n",
      "Non-constant expressions cannot be multiplied\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pulp\\pulp.py:1316: UserWarning: Spaces are not permitted in the name. Converted to '_'\n",
      "  warnings.warn(\"Spaces are not permitted in the name. Converted to '_'\")\n"
     ]
    }
   ],
   "source": [
    "# Priorities: [recipe tax, pall enriched ammonia, additional vector cost]\n",
    "priority_ratio = 9000/0.95 # Smallest/biggest\n",
    "\n",
    "from pulp import LpProblem, LpMinimize, LpBinary, LpVariable, value, lpSum, lpDot\n",
    "\n",
    "problem = LpProblem(\"min input test\", LpMinimize)\n",
    "recipe_vars = LpVariable.dicts(\"recipe\",  [\"lcr pall met pow recycle\", \"lcr repre\", \"sifter salt recycle\"],0)\n",
    "variables =  [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\", \"repre salt\"] \n",
    "# Filtered only by things that are ever an input\n",
    "inputs = [\"ammonia\", \"pall enriched ammonia\", \"pall met pow\", \"pall salt\"] \n",
    "explicit_inputs = [\"pall enriched ammonia\"]\n",
    "explicit_input_amounts = LpVariable.dicts(\"input\", explicit_inputs, 0)\n",
    "# Filtered to remove explicit inputs\n",
    "additional_inputs = [\"ammonia\", \"pall met pow\", \"pall salt\"] \n",
    "additional_input_amounts = LpVariable.dicts(\"input\", additional_inputs, 0)\n",
    "additional_input_switches = LpVariable.dicts(\"in_switch\", additional_inputs, cat=LpBinary)\n",
    "try:\n",
    "    for item, recipe_coeffs, target in zip(variables, pall_loop, target_vector):\n",
    "        # To reach each target amount, use a combination of the recipe outputs and switched inputs\n",
    "        # The amount for each input is unlimited, but there is a high cost for switching each one on\n",
    "        if item in explicit_inputs:\n",
    "            input_term = explicit_input_amounts[item]\n",
    "        elif item in additional_inputs:\n",
    "            input_term = additional_input_amounts[item] * additional_input_switches[item]\n",
    "        else:\n",
    "            input_term = 0\n",
    "        problem += lpDot(recipe_vars.values(), recipe_coeffs) + input_term >= target\n",
    "        \n",
    "    # Objective, in increasing order of priority:\n",
    "    # 1: Per-recipe tax\n",
    "    # (2, n-1): explicit costs to minimize (explicit inputs)\n",
    "    # n: High-cost additional inputs\n",
    "    problem += (priority_ratio**0 * lpSum(recipe_vars.values())\n",
    "        + priority_ratio**1 * explicit_input_amounts[\"pall enriched ammonia\"]\n",
    "        + priority_ratio**2 * lpSum(additional_input_switches))\n",
    "except TypeError as e:\n",
    "    print(\"Well poop.\")\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little essay about a new approach to solve this which-inputs-should-we-choose problem:\n",
    "\n",
    "# Alright, so making the linear optimizer solve for minimal inputs while also solving the problem ain't going to work.\n",
    "# ... because this formulation is quadratic and I can't think of a nice model that isn't.\n",
    "# ... we could get rid of the toggle and treat new inputs cumulatively as the highest priority class\n",
    "# ... but that has lots of edge cases and naturally gives a higher weight to minimizing large-number stuff, like fluids.\n",
    "# ... we could counteract *that* by normalizing quantities (so 9000L of oxygen becomes 9kL of oxygen, or a less nice unit)\n",
    "# ... but I can't think of a good normalization scheme that doesn't have problems with the different ranges of quantities between recipes.\n",
    "\n",
    "# New insight: Focus on solving for minimal inputs first, then solve problem.\n",
    "# Model this as a cover problem: we want to find the smallest set of inputs which reaches the inputs of all recipes.\n",
    "\n",
    "# We can once again use Linear Optimization to solve this problem.\n",
    "# We want to find the minimum number of inputs we must provide so that every recipe *can* be run.\n",
    "# We want to prioritize hitting every recipe, *then* minimizing the number of inputs.\n",
    "# Note that the linear optimizer might not use all resources if it choses not to include a relevant recipe in a solution.\n",
    "# Note that if you can run a parent recipe (e.g. ammonia and oxygen for nitric acid), \n",
    "# ... you can run descendent recipes (e.g. nitric acid [and ammonia] for ammonium chloride)\n",
    "\n",
    "# I'm going to model this as a bipartite graph in my head.\n",
    "# - Every resource that is ever an input to any recipe becomes a requirement (constraint in LP terms)\n",
    "#       - (one for oxygen, hydrochloric, ilmenite, whatever)\n",
    "#       - These are nodes on the right-hand side of the graph.\n",
    "#       - These are the inputs to \"cover\" with as few new/raw/actual inputs as possible. \n",
    "#       - I will call them \"requirement\" resources to avoid confusing myself.\n",
    "# - We also take this same list of inputs and make a binary (on or off) variable for every resource\n",
    "#       - Picture these as nodes on the left-hand side of the graph\n",
    "#       - Turning on these inputs corresponds to selecting that variable as an input.\n",
    "#       - I will call them \"providable\" resources to avoid confusing myself.\n",
    "# - In graph terms, we put an edge between every providable resource and the requirements it covers. This includes:\n",
    "#       - The resource itself (providing oxygen obviously covers oxygen requirements)\n",
    "#       - For every recipe which uses this resource, cover all of its outputs\n",
    "#       - For all of *those* resources, keep covering - this becomes DFS.\n",
    "#       - In LP terms, every constraint is sum(every binary variable that covers this required resource) >= 1\n",
    "# - Finally, the objective is the minimize the sum of all those binary variables (aka find fewest selected inputs)\n",
    "# - As a preprocessing step, all requirements that are indirectly covered by explicitly provided inputs can be deleted.\n",
    "\n",
    "# Something in my head tickles that this is NP-Complete, but I don't feel like putting in the work to test/prove it.\n",
    "# Regardless, LP solvers can totally tackle NPC problems like Knapsack (and they're reasonably optimized about it)\n",
    "\n",
    "# One big issue with this approach: selecting a valuable resource before a loop \n",
    "# (for example, palladium salt dust, which loops around and indirectly supplies *many* recipes)\n",
    "# ... will have high value and cover many resources. \n",
    "# Theory #1: We could use a heuristic-based \"cyclic graph toposort\" to minimize back-edges (loop-backs)\n",
    "# ... use that sort to form a DAG that mostly moves ingredient->output, and then use this algorithm\n",
    "# Theory #2: By the nature of most GTNH recipe graphs, especially when at least one start-of-the-chain ingredient has been provided,\n",
    "# ... a solution which uses just-before-a-loop resources as an input won't usually be \"minimal\".\n",
    "# Further, this algorithm doesn't need to *perfectly* solve this problem, \n",
    "# ... because the user can fix wierd behavior by explicitly providing more resources.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One example is a loop in the palladium component of the platline,\n",
    "# which inputs palladium enriched ammonia and loops that and pall met pow dust\n",
    "# [ammonia, pall enriched ammonia, pall met pow, pall salt, repre pall]\n",
    "# and cols are:\n",
    "# [lcr pall met pow recycle, lcr repre, sifter salt recycle]\n",
    "pall_loop = [\n",
    "    [-1000, 0,      0],\n",
    "    [1000,  -9000,  0],\n",
    "    [-1,    -9,     0.95],\n",
    "    [0,     16,     -1],\n",
    "    [0,     2,      0],\n",
    "]\n",
    "target_vector = [0, 0, 0, 0, 10]\n",
    "item_recipe_covers = {\n",
    "    \"ammonia\": {\"lcr pall met pow recycle\": {\"pall enriched ammonia\"}},\n",
    "    \"pall met pow\": {\"lcr pall met pow recycle\": {\"pall enriched ammonia\"}},\n",
    "    \"pall enriched ammonia\": {\"lcr repre\": {\"pall salt\", \"repre pall\"}},\n",
    "    \"pall met pow\": {\"lcr repre\": {\"pall salt\", \"repre pall\"}},\n",
    "    \"pall salt\":{\"sifter salt recycle\": {\"pall met pow\"}}\n",
    "}\n",
    "pall_recipes = {\n",
    "    \"lcr pall met pow recycle\": {\n",
    "        \"I\": {\"ammonia\":1000, \"pall met pow\": 1},\n",
    "        \"O\": {\"pall enriched ammonia\": 1000},\n",
    "    },\n",
    "    \"lcr repre\": {\n",
    "        \"I\": {\"pall enriched ammonia\": 9000, \"pall met pow\": 9},\n",
    "        \"O\": {\"pall salt\": 16, \"repre pall\": 2},\n",
    "    },\n",
    "    \"sifter salt recycle\": {\n",
    "        \"I\": {\"pall salt\": 1},\n",
    "        \"O\": {\"pall met pow\": 0.95},\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from src.data.loadMachines import recipesFromConfig\n",
    "def genSlug(self, s, try_acronym=False):\n",
    "    slug = re.sub(r\"[^a-zA-Z0-9_]\", \"\", re.sub(r\"\\W+\", \"_\", s.lower()))\n",
    "    words = slug.split(\"_\")\n",
    "    if len(slug) > 25 or (try_acronym and len(words)>=2):\n",
    "        return \"\".join(word[0] for word in words)\n",
    "    else:\n",
    "        return slug\n",
    "\n",
    "def genRecipeNames(recipes):\n",
    "    node_recipes = {\n",
    "        node: self.graph.recipes[node]\n",
    "        for node in self.graph.nodes\n",
    "        if node not in [\"source\", \"sink\"]\n",
    "    }\n",
    "    counter = Counter()\n",
    "    name_map = {\"sink\": \"sink\", \"source\": \"source\"}\n",
    "    for node, recipe in node_recipes.items():\n",
    "        name = genSlug(recipe.machine, True) + \"_\" + genSlug(recipe.I[0].name)\n",
    "        if name in counter:\n",
    "            counter[name] += 1\n",
    "            name += f\"_{counter[name]}\"\n",
    "        name_map[node] = name\n",
    "    return name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lcr pall met pow recycle {'I': {'ammonia': 1000, 'pall met pow': 1}, 'O': {'pall enriched ammonia': 1000}}\n",
      "lcr repre {'I': {'pall enriched ammonia': 9000, 'pall met pow': 9}, 'O': {'pall salt': 16, 'repre pall': 2}}\n",
      "sifter salt recycle {'I': {'pall salt': 1}, 'O': {'pall met pow': 0.95}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ammonia': {'ammonia',\n",
       "  'pall enriched ammonia',\n",
       "  'pall met pow',\n",
       "  'pall salt',\n",
       "  'repre pall'},\n",
       " 'pall met pow': {'pall enriched ammonia',\n",
       "  'pall met pow',\n",
       "  'pall salt',\n",
       "  'repre pall'},\n",
       " 'pall enriched ammonia': {'pall enriched ammonia',\n",
       "  'pall met pow',\n",
       "  'pall salt',\n",
       "  'repre pall'},\n",
       " 'pall salt': {'pall enriched ammonia',\n",
       "  'pall met pow',\n",
       "  'pall salt',\n",
       "  'repre pall'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getItemCovers(recipes):\n",
    "    item_covers = {}\n",
    "\n",
    "    # Cheeky DFS for each item to figure out what it covers.\n",
    "    # This could be done all-at-once with some shenanigans, but I think we want to not allow loops on a per-item basis\n",
    "    # My gut is telling me that will be a slightly more restricted/less-prone-to-error heuristic.\n",
    "    item_to_covered_recipes = {}\n",
    "    recipe_to_covered_items = {}\n",
    "    items_to_cover = set()\n",
    "    for covered_recipe, io in recipes.items():\n",
    "        print(covered_recipe, io)\n",
    "        for ing in io[\"I\"].keys():\n",
    "            item_to_covered_recipes[ing] = item_to_covered_recipes.get(ing, []) + [covered_recipe]\n",
    "            items_to_cover.add(ing)\n",
    "        for out in io[\"O\"].keys():\n",
    "            recipe_to_covered_items[covered_recipe] = recipe_to_covered_items.get(covered_recipe, []) + [out]\n",
    "\n",
    "    for item in item_recipe_covers:\n",
    "        used_recipes = set()\n",
    "        covered_items = {item}\n",
    "        frontier = [item]\n",
    "        while not len(frontier) == 0:\n",
    "            covered_item = frontier.pop()\n",
    "            if covered_item not in item_to_covered_recipes: continue # item covers no recipes\n",
    "            for covered_recipe in item_to_covered_recipes[covered_item]:\n",
    "                if covered_recipe in used_recipes: continue # Recipe already used (we've looped)\n",
    "                used_recipes.add(covered_recipe)\n",
    "                if covered_recipe not in recipe_to_covered_items: continue # recipe covers no items (we deleted its items in preprocessing)\n",
    "                for outgoing_item in recipe_to_covered_items[covered_recipe]:\n",
    "                    if outgoing_item in covered_items: continue # We've already hit this item\n",
    "                    covered_items.add(outgoing_item)\n",
    "                    frontier.append(outgoing_item)\n",
    "        item_covers[item] = covered_items\n",
    "    return item_covers\n",
    "getItemCovers(pall_recipes)\n",
    "# Only ammonia covers ammonia (good), but I think this loopy example is a bad example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Ingredient(name='bauxite dust', quant=39)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import yaml\n",
    "\n",
    "bauxite_example_project = \"223_bauxite_line.yaml\"\n",
    "recipes = recipesFromConfig(bauxite_example_project)\n",
    "# getItemCovers(bauxite_recipes)\n",
    "recipes[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
